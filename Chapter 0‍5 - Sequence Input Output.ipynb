{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter ‍5 Sequence Input/Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this chapter we’ll discuss in more detail the `Bio.SeqIO` module, which was briefly introduced in Chapter ‍2 and also used in Chapter ‍4. This aims to provide a simple interface for working with assorted sequence file formats in a uniform way. See also the `Bio.SeqIO` wiki page [BioPython](http://biopython.org/wiki/SeqIO), and the built in documentation (also online):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package Bio.SeqIO in Bio:\n",
      "\n",
      "NAME\n",
      "    Bio.SeqIO - Sequence input/output as SeqRecord objects.\n",
      "\n",
      "DESCRIPTION\n",
      "    Bio.SeqIO is also documented at SeqIO_ and by a whole chapter in our tutorial:\n",
      "    \n",
      "      - `HTML Tutorial`_\n",
      "      - `PDF Tutorial`_\n",
      "    \n",
      "    .. _SeqIO: http://biopython.org/wiki/SeqIO\n",
      "    .. _`HTML Tutorial`: http://biopython.org/DIST/docs/tutorial/Tutorial.html\n",
      "    .. _`PDF Tutorial`: http://biopython.org/DIST/docs/tutorial/Tutorial.pdf\n",
      "    \n",
      "    Input\n",
      "    -----\n",
      "    The main function is Bio.SeqIO.parse(...) which takes an input file handle\n",
      "    (or in recent versions of Biopython alternatively a filename as a string),\n",
      "    and format string.  This returns an iterator giving SeqRecord objects:\n",
      "    \n",
      "    >>> from Bio import SeqIO\n",
      "    >>> for record in SeqIO.parse(\"Fasta/f002\", \"fasta\"):\n",
      "    ...     print(\"%s %i\" % (record.id, len(record)))\n",
      "    gi|1348912|gb|G26680|G26680 633\n",
      "    gi|1348917|gb|G26685|G26685 413\n",
      "    gi|1592936|gb|G29385|G29385 471\n",
      "    \n",
      "    Note that the parse() function will invoke the relevant parser for the\n",
      "    format with its default settings.  You may want more control, in which case\n",
      "    you need to create a format specific sequence iterator directly.\n",
      "    \n",
      "    Some of these parsers are wrappers around low-level parsers which build up\n",
      "    SeqRecord objects for the consistent SeqIO interface. In cases where the\n",
      "    run-time is critical, such as large FASTA or FASTQ files, calling these\n",
      "    underlying parsers will be much faster - in this case these generator\n",
      "    functions which return tuples of strings:\n",
      "    \n",
      "    >>> from Bio.SeqIO.FastaIO import SimpleFastaParser\n",
      "    >>> from Bio.SeqIO.QualityIO import FastqGeneralIterator\n",
      "    \n",
      "    \n",
      "    Input - Single Records\n",
      "    ----------------------\n",
      "    If you expect your file to contain one-and-only-one record, then we provide\n",
      "    the following 'helper' function which will return a single SeqRecord, or\n",
      "    raise an exception if there are no records or more than one record:\n",
      "    \n",
      "    >>> from Bio import SeqIO\n",
      "    >>> record = SeqIO.read(\"Fasta/f001\", \"fasta\")\n",
      "    >>> print(\"%s %i\" % (record.id, len(record)))\n",
      "    gi|3318709|pdb|1A91| 79\n",
      "    \n",
      "    This style is useful when you expect a single record only (and would\n",
      "    consider multiple records an error).  For example, when dealing with GenBank\n",
      "    files for bacterial genomes or chromosomes, there is normally only a single\n",
      "    record.  Alternatively, use this with a handle when downloading a single\n",
      "    record from the internet.\n",
      "    \n",
      "    However, if you just want the first record from a file containing multiple\n",
      "    record, use the next() function on the iterator:\n",
      "    \n",
      "    >>> from Bio import SeqIO\n",
      "    >>> record = next(SeqIO.parse(\"Fasta/f002\", \"fasta\"))\n",
      "    >>> print(\"%s %i\" % (record.id, len(record)))\n",
      "    gi|1348912|gb|G26680|G26680 633\n",
      "    \n",
      "    The above code will work as long as the file contains at least one record.\n",
      "    Note that if there is more than one record, the remaining records will be\n",
      "    silently ignored.\n",
      "    \n",
      "    \n",
      "    Input - Multiple Records\n",
      "    ------------------------\n",
      "    For non-interlaced files (e.g. Fasta, GenBank, EMBL) with multiple records\n",
      "    using a sequence iterator can save you a lot of memory (RAM).  There is\n",
      "    less benefit for interlaced file formats (e.g. most multiple alignment file\n",
      "    formats).  However, an iterator only lets you access the records one by one.\n",
      "    \n",
      "    If you want random access to the records by number, turn this into a list:\n",
      "    \n",
      "    >>> from Bio import SeqIO\n",
      "    >>> records = list(SeqIO.parse(\"Fasta/f002\", \"fasta\"))\n",
      "    >>> len(records)\n",
      "    3\n",
      "    >>> print(records[1].id)\n",
      "    gi|1348917|gb|G26685|G26685\n",
      "    \n",
      "    If you want random access to the records by a key such as the record id,\n",
      "    turn the iterator into a dictionary:\n",
      "    \n",
      "    >>> from Bio import SeqIO\n",
      "    >>> record_dict = SeqIO.to_dict(SeqIO.parse(\"Fasta/f002\", \"fasta\"))\n",
      "    >>> len(record_dict)\n",
      "    3\n",
      "    >>> print(len(record_dict[\"gi|1348917|gb|G26685|G26685\"]))\n",
      "    413\n",
      "    \n",
      "    However, using list() or the to_dict() function will load all the records\n",
      "    into memory at once, and therefore is not possible on very large files.\n",
      "    Instead, for *some* file formats Bio.SeqIO provides an indexing approach\n",
      "    providing dictionary like access to any record. For example,\n",
      "    \n",
      "    >>> from Bio import SeqIO\n",
      "    >>> record_dict = SeqIO.index(\"Fasta/f002\", \"fasta\")\n",
      "    >>> len(record_dict)\n",
      "    3\n",
      "    >>> print(len(record_dict[\"gi|1348917|gb|G26685|G26685\"]))\n",
      "    413\n",
      "    >>> record_dict.close()\n",
      "    \n",
      "    Many but not all of the supported input file formats can be indexed like\n",
      "    this. For example \"fasta\", \"fastq\", \"qual\" and even the binary format \"sff\"\n",
      "    work, but alignment formats like \"phylip\", \"clustalw\" and \"nexus\" will not.\n",
      "    \n",
      "    In most cases you can also use SeqIO.index to get the record from the file\n",
      "    as a raw string (not a SeqRecord). This can be useful for example to extract\n",
      "    a sub-set of records from a file where SeqIO cannot output the file format\n",
      "    (e.g. the plain text SwissProt format, \"swiss\") or where it is important to\n",
      "    keep the output 100% identical to the input). For example,\n",
      "    \n",
      "    >>> from Bio import SeqIO\n",
      "    >>> record_dict = SeqIO.index(\"Fasta/f002\", \"fasta\")\n",
      "    >>> len(record_dict)\n",
      "    3\n",
      "    >>> print(record_dict.get_raw(\"gi|1348917|gb|G26685|G26685\").decode())\n",
      "    >gi|1348917|gb|G26685|G26685 human STS STS_D11734.\n",
      "    CGGAGCCAGCGAGCATATGCTGCATGAGGACCTTTCTATCTTACATTATGGCTGGGAATCTTACTCTTTC\n",
      "    ATCTGATACCTTGTTCAGATTTCAAAATAGTTGTAGCCTTATCCTGGTTTTACAGATGTGAAACTTTCAA\n",
      "    GAGATTTACTGACTTTCCTAGAATAGTTTCTCTACTGGAAACCTGATGCTTTTATAAGCCATTGTGATTA\n",
      "    GGATGACTGTTACAGGCTTAGCTTTGTGTGAAANCCAGTCACCTTTCTCCTAGGTAATGAGTAGTGCTGT\n",
      "    TCATATTACTNTAAGTTCTATAGCATACTTGCNATCCTTTANCCATGCTTATCATANGTACCATTTGAGG\n",
      "    AATTGNTTTGCCCTTTTGGGTTTNTTNTTGGTAAANNNTTCCCGGGTGGGGGNGGTNNNGAAA\n",
      "    <BLANKLINE>\n",
      "    >>> print(record_dict[\"gi|1348917|gb|G26685|G26685\"].format(\"fasta\"))\n",
      "    >gi|1348917|gb|G26685|G26685 human STS STS_D11734.\n",
      "    CGGAGCCAGCGAGCATATGCTGCATGAGGACCTTTCTATCTTACATTATGGCTGGGAATC\n",
      "    TTACTCTTTCATCTGATACCTTGTTCAGATTTCAAAATAGTTGTAGCCTTATCCTGGTTT\n",
      "    TACAGATGTGAAACTTTCAAGAGATTTACTGACTTTCCTAGAATAGTTTCTCTACTGGAA\n",
      "    ACCTGATGCTTTTATAAGCCATTGTGATTAGGATGACTGTTACAGGCTTAGCTTTGTGTG\n",
      "    AAANCCAGTCACCTTTCTCCTAGGTAATGAGTAGTGCTGTTCATATTACTNTAAGTTCTA\n",
      "    TAGCATACTTGCNATCCTTTANCCATGCTTATCATANGTACCATTTGAGGAATTGNTTTG\n",
      "    CCCTTTTGGGTTTNTTNTTGGTAAANNNTTCCCGGGTGGGGGNGGTNNNGAAA\n",
      "    <BLANKLINE>\n",
      "    >>> record_dict.close()\n",
      "    \n",
      "    Here the original file and what Biopython would output differ in the line\n",
      "    wrapping. Also note that the get_raw method will return a bytes object,\n",
      "    hence the use of decode to turn it into a string.\n",
      "    \n",
      "    Also note that the get_raw method will preserve the newline endings. This\n",
      "    example FASTQ file uses Unix style endings (b\"\\n\" only),\n",
      "    \n",
      "    >>> from Bio import SeqIO\n",
      "    >>> fastq_dict = SeqIO.index(\"Quality/example.fastq\", \"fastq\")\n",
      "    >>> len(fastq_dict)\n",
      "    3\n",
      "    >>> raw = fastq_dict.get_raw(\"EAS54_6_R1_2_1_540_792\")\n",
      "    >>> raw.count(b\"\\n\")\n",
      "    4\n",
      "    >>> raw.count(b\"\\r\\n\")\n",
      "    0\n",
      "    >>> b\"\\r\" in raw\n",
      "    False\n",
      "    >>> len(raw)\n",
      "    78\n",
      "    >>> fastq_dict.close()\n",
      "    \n",
      "    Here is the same file but using DOS/Windows new lines (b\"\\r\\n\" instead),\n",
      "    \n",
      "    >>> from Bio import SeqIO\n",
      "    >>> fastq_dict = SeqIO.index(\"Quality/example_dos.fastq\", \"fastq\")\n",
      "    >>> len(fastq_dict)\n",
      "    3\n",
      "    >>> raw = fastq_dict.get_raw(\"EAS54_6_R1_2_1_540_792\")\n",
      "    >>> raw.count(b\"\\n\")\n",
      "    4\n",
      "    >>> raw.count(b\"\\r\\n\")\n",
      "    4\n",
      "    >>> b\"\\r\\n\" in raw\n",
      "    True\n",
      "    >>> len(raw)\n",
      "    82\n",
      "    >>> fastq_dict.close()\n",
      "    \n",
      "    Because this uses two bytes for each new line, the file is longer than\n",
      "    the Unix equivalent with only one byte.\n",
      "    \n",
      "    \n",
      "    Input - Alignments\n",
      "    ------------------\n",
      "    You can read in alignment files as alignment objects using Bio.AlignIO.\n",
      "    Alternatively, reading in an alignment file format via Bio.SeqIO will give\n",
      "    you a SeqRecord for each row of each alignment:\n",
      "    \n",
      "    >>> from Bio import SeqIO\n",
      "    >>> for record in SeqIO.parse(\"Clustalw/hedgehog.aln\", \"clustal\"):\n",
      "    ...     print(\"%s %i\" % (record.id, len(record)))\n",
      "    gi|167877390|gb|EDS40773.1| 447\n",
      "    gi|167234445|ref|NP_001107837. 447\n",
      "    gi|74100009|gb|AAZ99217.1| 447\n",
      "    gi|13990994|dbj|BAA33523.2| 447\n",
      "    gi|56122354|gb|AAV74328.1| 447\n",
      "    \n",
      "    \n",
      "    Output\n",
      "    ------\n",
      "    Use the function Bio.SeqIO.write(...), which takes a complete set of\n",
      "    SeqRecord objects (either as a list, or an iterator), an output file handle\n",
      "    (or in recent versions of Biopython an output filename as a string) and of\n",
      "    course the file format::\n",
      "    \n",
      "      from Bio import SeqIO\n",
      "      records = ...\n",
      "      SeqIO.write(records, \"example.faa\", \"fasta\")\n",
      "    \n",
      "    Or, using a handle::\n",
      "    \n",
      "        from Bio import SeqIO\n",
      "        records = ...\n",
      "        with open(\"example.faa\", \"w\") as handle:\n",
      "          SeqIO.write(records, handle, \"fasta\")\n",
      "    \n",
      "    You are expected to call this function once (with all your records) and if\n",
      "    using a handle, make sure you close it to flush the data to the hard disk.\n",
      "    \n",
      "    \n",
      "    Output - Advanced\n",
      "    -----------------\n",
      "    The effect of calling write() multiple times on a single file will vary\n",
      "    depending on the file format, and is best avoided unless you have a strong\n",
      "    reason to do so.\n",
      "    \n",
      "    If you give a filename, then each time you call write() the existing file\n",
      "    will be overwritten. For sequential files formats (e.g. fasta, genbank) each\n",
      "    \"record block\" holds a single sequence.  For these files it would probably\n",
      "    be safe to call write() multiple times by re-using the same handle.\n",
      "    \n",
      "    However, trying this for certain alignment formats (e.g. phylip, clustal,\n",
      "    stockholm) would have the effect of concatenating several multiple sequence\n",
      "    alignments together.  Such files are created by the PHYLIP suite of programs\n",
      "    for bootstrap analysis, but it is clearer to do this via Bio.AlignIO instead.\n",
      "    \n",
      "    Worse, many fileformats have an explicit header and/or footer structure\n",
      "    (e.g. any XMl format, and most binary file formats like SFF). Here making\n",
      "    multiple calls to write() will result in an invalid file.\n",
      "    \n",
      "    \n",
      "    Conversion\n",
      "    ----------\n",
      "    The Bio.SeqIO.convert(...) function allows an easy interface for simple\n",
      "    file format conversions. Additionally, it may use file format specific\n",
      "    optimisations so this should be the fastest way too.\n",
      "    \n",
      "    In general however, you can combine the Bio.SeqIO.parse(...) function with\n",
      "    the Bio.SeqIO.write(...) function for sequence file conversion. Using\n",
      "    generator expressions or generator functions provides a memory efficient way\n",
      "    to perform filtering or other extra operations as part of the process.\n",
      "    \n",
      "    \n",
      "    File Formats\n",
      "    ------------\n",
      "    When specifying the file format, use lowercase strings.  The same format\n",
      "    names are also used in Bio.AlignIO and include the following:\n",
      "    \n",
      "        - abi     - Applied Biosystem's sequencing trace format\n",
      "        - abi-trim - Same as \"abi\" but with quality trimming with Mott's algorithm\n",
      "        - ace     - Reads the contig sequences from an ACE assembly file.\n",
      "        - cif-atom - Uses Bio.PDB.MMCIFParser to determine the (partial) protein\n",
      "          sequence as it appears in the structure based on the atomic coordinates.\n",
      "        - cif-seqres - Reads a macromolecular Crystallographic Information File\n",
      "          (mmCIF) file to determine the complete protein sequence as defined by the\n",
      "          _pdbx_poly_seq_scheme records.\n",
      "        - embl    - The EMBL flat file format. Uses Bio.GenBank internally.\n",
      "        - fasta   - The generic sequence file format where each record starts with\n",
      "          an identifier line starting with a \">\" character, followed by\n",
      "          lines of sequence.\n",
      "        - fasta-2line - Stricter interpretation of the FASTA format using exactly\n",
      "          two lines per record (no line wrapping).\n",
      "        - fastq   - A \"FASTA like\" format used by Sanger which also stores PHRED\n",
      "          sequence quality values (with an ASCII offset of 33).\n",
      "        - fastq-sanger - An alias for \"fastq\" for consistency with BioPerl and EMBOSS\n",
      "        - fastq-solexa - Original Solexa/Illumnia variant of the FASTQ format which\n",
      "          encodes Solexa quality scores (not PHRED quality scores) with an\n",
      "          ASCII offset of 64.\n",
      "        - fastq-illumina - Solexa/Illumina 1.3 to 1.7 variant of the FASTQ format\n",
      "          which encodes PHRED quality scores with an ASCII offset of 64\n",
      "          (not 33). Note as of version 1.8 of the CASAVA pipeline Illumina\n",
      "          will produce FASTQ files using the standard Sanger encoding.\n",
      "        - gck     - Gene Construction Kit's format.\n",
      "        - genbank - The GenBank or GenPept flat file format.\n",
      "        - gb      - An alias for \"genbank\", for consistency with NCBI Entrez Utilities\n",
      "        - ig      - The IntelliGenetics file format, apparently the same as the\n",
      "          MASE alignment format.\n",
      "        - imgt    - An EMBL like format from IMGT where the feature tables are more\n",
      "          indented to allow for longer feature types.\n",
      "        - nib     - UCSC's nib file format for nucleotide sequences, which uses one\n",
      "          nibble (4 bits) to represent each nucleotide, and stores two nucleotides in\n",
      "          one byte.\n",
      "        - pdb-seqres -  Reads a Protein Data Bank (PDB) file to determine the\n",
      "          complete protein sequence as it appears in the header (no dependencies).\n",
      "        - pdb-atom - Uses Bio.PDB to determine the (partial) protein sequence as\n",
      "          it appears in the structure based on the atom coordinate section of the\n",
      "          file (requires NumPy for Bio.PDB).\n",
      "        - phd     - Output from PHRED, used by PHRAP and CONSED for input.\n",
      "        - pir     - A \"FASTA like\" format introduced by the National Biomedical\n",
      "          Research Foundation (NBRF) for the Protein Information Resource\n",
      "          (PIR) database, now part of UniProt.\n",
      "        - seqxml  - SeqXML, simple XML format described in Schmitt et al (2011).\n",
      "        - sff     - Standard Flowgram Format (SFF), typical output from Roche 454.\n",
      "        - sff-trim - Standard Flowgram Format (SFF) with given trimming applied.\n",
      "        - snapgene - SnapGene's native format.\n",
      "        - swiss   - Plain text Swiss-Prot aka UniProt format.\n",
      "        - tab     - Simple two column tab separated sequence files, where each\n",
      "          line holds a record's identifier and sequence. For example,\n",
      "          this is used as by Aligent's eArray software when saving\n",
      "          microarray probes in a minimal tab delimited text file.\n",
      "        - qual    - A \"FASTA like\" format holding PHRED quality values from\n",
      "          sequencing DNA, but no actual sequences (usually provided\n",
      "          in separate FASTA files).\n",
      "        - uniprot-xml - The UniProt XML format (replacement for the SwissProt plain\n",
      "          text format which we call \"swiss\")\n",
      "        - xdna        - DNA Strider's and SerialCloner's native format.\n",
      "    \n",
      "    Note that while Bio.SeqIO can read all the above file formats, it cannot\n",
      "    write to all of them.\n",
      "    \n",
      "    You can also use any file format supported by Bio.AlignIO, such as \"nexus\",\n",
      "    \"phylip\" and \"stockholm\", which gives you access to the individual sequences\n",
      "    making up each alignment as SeqRecords.\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    AbiIO\n",
      "    AceIO\n",
      "    FastaIO\n",
      "    GckIO\n",
      "    IgIO\n",
      "    InsdcIO\n",
      "    Interfaces\n",
      "    NibIO\n",
      "    PdbIO\n",
      "    PhdIO\n",
      "    PirIO\n",
      "    QualityIO\n",
      "    SeqXmlIO\n",
      "    SffIO\n",
      "    SnapGeneIO\n",
      "    SwissIO\n",
      "    TabIO\n",
      "    TwoBitIO\n",
      "    UniprotIO\n",
      "    XdnaIO\n",
      "    _index\n",
      "    _twoBitIO\n",
      "\n",
      "FUNCTIONS\n",
      "    convert(in_file, in_format, out_file, out_format, molecule_type=None)\n",
      "        Convert between two sequence file formats, return number of records.\n",
      "        \n",
      "        Arguments:\n",
      "         - in_file - an input handle or filename\n",
      "         - in_format - input file format, lower case string\n",
      "         - out_file - an output handle or filename\n",
      "         - out_format - output file format, lower case string\n",
      "         - molecule_type - optional molecule type to apply, string containing\n",
      "           \"DNA\", \"RNA\" or \"protein\".\n",
      "        \n",
      "        **NOTE** - If you provide an output filename, it will be opened which will\n",
      "        overwrite any existing file without warning.\n",
      "        \n",
      "        The idea here is that while doing this will work::\n",
      "        \n",
      "            from Bio import SeqIO\n",
      "            records = SeqIO.parse(in_handle, in_format)\n",
      "            count = SeqIO.write(records, out_handle, out_format)\n",
      "        \n",
      "        it is shorter to write::\n",
      "        \n",
      "            from Bio import SeqIO\n",
      "            count = SeqIO.convert(in_handle, in_format, out_handle, out_format)\n",
      "        \n",
      "        Also, Bio.SeqIO.convert is faster for some conversions as it can make some\n",
      "        optimisations.\n",
      "        \n",
      "        For example, going from a filename to a handle:\n",
      "        \n",
      "        >>> from Bio import SeqIO\n",
      "        >>> from io import StringIO\n",
      "        >>> handle = StringIO(\"\")\n",
      "        >>> SeqIO.convert(\"Quality/example.fastq\", \"fastq\", handle, \"fasta\")\n",
      "        3\n",
      "        >>> print(handle.getvalue())\n",
      "        >EAS54_6_R1_2_1_413_324\n",
      "        CCCTTCTTGTCTTCAGCGTTTCTCC\n",
      "        >EAS54_6_R1_2_1_540_792\n",
      "        TTGGCAGGCCAAGGCCGATGGATCA\n",
      "        >EAS54_6_R1_2_1_443_348\n",
      "        GTTGCTTCTGGCGTGGGTGGGGGGG\n",
      "        <BLANKLINE>\n",
      "        \n",
      "        Note some formats like SeqXML require you to specify the molecule type\n",
      "        when it cannot be determined by the parser:\n",
      "        \n",
      "        >>> from Bio import SeqIO\n",
      "        >>> from io import BytesIO\n",
      "        >>> handle = BytesIO()\n",
      "        >>> SeqIO.convert(\"Quality/example.fastq\", \"fastq\", handle, \"seqxml\", \"DNA\")\n",
      "        3\n",
      "    \n",
      "    index(filename, format, alphabet=None, key_function=None)\n",
      "        Indexes a sequence file and returns a dictionary like object.\n",
      "        \n",
      "        Arguments:\n",
      "         - filename - string giving name of file to be indexed\n",
      "         - format   - lower case string describing the file format\n",
      "         - alphabet - no longer used, leave as None\n",
      "         - key_function - Optional callback function which when given a\n",
      "           SeqRecord identifier string should return a unique key for the\n",
      "           dictionary.\n",
      "        \n",
      "        This indexing function will return a dictionary like object, giving the\n",
      "        SeqRecord objects as values.\n",
      "        \n",
      "        As of Biopython 1.69, this will preserve the ordering of the records in\n",
      "        file when iterating over the entries.\n",
      "        \n",
      "        >>> from Bio import SeqIO\n",
      "        >>> records = SeqIO.index(\"Quality/example.fastq\", \"fastq\")\n",
      "        >>> len(records)\n",
      "        3\n",
      "        >>> list(records)  # make a list of the keys\n",
      "        ['EAS54_6_R1_2_1_413_324', 'EAS54_6_R1_2_1_540_792', 'EAS54_6_R1_2_1_443_348']\n",
      "        >>> print(records[\"EAS54_6_R1_2_1_540_792\"].format(\"fasta\"))\n",
      "        >EAS54_6_R1_2_1_540_792\n",
      "        TTGGCAGGCCAAGGCCGATGGATCA\n",
      "        <BLANKLINE>\n",
      "        >>> \"EAS54_6_R1_2_1_540_792\" in records\n",
      "        True\n",
      "        >>> print(records.get(\"Missing\", None))\n",
      "        None\n",
      "        >>> records.close()\n",
      "        \n",
      "        If the file is BGZF compressed, this is detected automatically. Ordinary\n",
      "        GZIP files are not supported:\n",
      "        \n",
      "        >>> from Bio import SeqIO\n",
      "        >>> records = SeqIO.index(\"Quality/example.fastq.bgz\", \"fastq\")\n",
      "        >>> len(records)\n",
      "        3\n",
      "        >>> print(records[\"EAS54_6_R1_2_1_540_792\"].seq)\n",
      "        TTGGCAGGCCAAGGCCGATGGATCA\n",
      "        >>> records.close()\n",
      "        \n",
      "        When you call the index function, it will scan through the file, noting\n",
      "        the location of each record. When you access a particular record via the\n",
      "        dictionary methods, the code will jump to the appropriate part of the\n",
      "        file and then parse that section into a SeqRecord.\n",
      "        \n",
      "        Note that not all the input formats supported by Bio.SeqIO can be used\n",
      "        with this index function. It is designed to work only with sequential\n",
      "        file formats (e.g. \"fasta\", \"gb\", \"fastq\") and is not suitable for any\n",
      "        interlaced file format (e.g. alignment formats such as \"clustal\").\n",
      "        \n",
      "        For small files, it may be more efficient to use an in memory Python\n",
      "        dictionary, e.g.\n",
      "        \n",
      "        >>> from Bio import SeqIO\n",
      "        >>> records = SeqIO.to_dict(SeqIO.parse(\"Quality/example.fastq\", \"fastq\"))\n",
      "        >>> len(records)\n",
      "        3\n",
      "        >>> list(records)  # make a list of the keys\n",
      "        ['EAS54_6_R1_2_1_413_324', 'EAS54_6_R1_2_1_540_792', 'EAS54_6_R1_2_1_443_348']\n",
      "        >>> print(records[\"EAS54_6_R1_2_1_540_792\"].format(\"fasta\"))\n",
      "        >EAS54_6_R1_2_1_540_792\n",
      "        TTGGCAGGCCAAGGCCGATGGATCA\n",
      "        <BLANKLINE>\n",
      "        \n",
      "        As with the to_dict() function, by default the id string of each record\n",
      "        is used as the key. You can specify a callback function to transform\n",
      "        this (the record identifier string) into your preferred key. For example:\n",
      "        \n",
      "        >>> from Bio import SeqIO\n",
      "        >>> def make_tuple(identifier):\n",
      "        ...     parts = identifier.split(\"_\")\n",
      "        ...     return int(parts[-2]), int(parts[-1])\n",
      "        >>> records = SeqIO.index(\"Quality/example.fastq\", \"fastq\",\n",
      "        ...                       key_function=make_tuple)\n",
      "        >>> len(records)\n",
      "        3\n",
      "        >>> list(records)  # make a list of the keys\n",
      "        [(413, 324), (540, 792), (443, 348)]\n",
      "        >>> print(records[(540, 792)].format(\"fasta\"))\n",
      "        >EAS54_6_R1_2_1_540_792\n",
      "        TTGGCAGGCCAAGGCCGATGGATCA\n",
      "        <BLANKLINE>\n",
      "        >>> (540, 792) in records\n",
      "        True\n",
      "        >>> \"EAS54_6_R1_2_1_540_792\" in records\n",
      "        False\n",
      "        >>> print(records.get(\"Missing\", None))\n",
      "        None\n",
      "        >>> records.close()\n",
      "        \n",
      "        Another common use case would be indexing an NCBI style FASTA file,\n",
      "        where you might want to extract the GI number from the FASTA identifier\n",
      "        to use as the dictionary key.\n",
      "        \n",
      "        Notice that unlike the to_dict() function, here the key_function does\n",
      "        not get given the full SeqRecord to use to generate the key. Doing so\n",
      "        would impose a severe performance penalty as it would require the file\n",
      "        to be completely parsed while building the index. Right now this is\n",
      "        usually avoided.\n",
      "        \n",
      "        See Also: Bio.SeqIO.index_db() and Bio.SeqIO.to_dict()\n",
      "    \n",
      "    index_db(index_filename, filenames=None, format=None, alphabet=None, key_function=None)\n",
      "        Index several sequence files and return a dictionary like object.\n",
      "        \n",
      "        The index is stored in an SQLite database rather than in memory (as in the\n",
      "        Bio.SeqIO.index(...) function).\n",
      "        \n",
      "        Arguments:\n",
      "         - index_filename - Where to store the SQLite index\n",
      "         - filenames - list of strings specifying file(s) to be indexed, or when\n",
      "           indexing a single file this can be given as a string.\n",
      "           (optional if reloading an existing index, but must match)\n",
      "         - format   - lower case string describing the file format\n",
      "           (optional if reloading an existing index, but must match)\n",
      "         - alphabet - no longer used, leave as None.\n",
      "         - key_function - Optional callback function which when given a\n",
      "           SeqRecord identifier string should return a unique\n",
      "           key for the dictionary.\n",
      "        \n",
      "        This indexing function will return a dictionary like object, giving the\n",
      "        SeqRecord objects as values:\n",
      "        \n",
      "        >>> from Bio import SeqIO\n",
      "        >>> files = [\"GenBank/NC_000932.faa\", \"GenBank/NC_005816.faa\"]\n",
      "        >>> def get_gi(name):\n",
      "        ...     parts = name.split(\"|\")\n",
      "        ...     i = parts.index(\"gi\")\n",
      "        ...     assert i != -1\n",
      "        ...     return parts[i+1]\n",
      "        >>> idx_name = \":memory:\" #use an in memory SQLite DB for this test\n",
      "        >>> records = SeqIO.index_db(idx_name, files, \"fasta\", key_function=get_gi)\n",
      "        >>> len(records)\n",
      "        95\n",
      "        >>> records[\"7525076\"].description\n",
      "        'gi|7525076|ref|NP_051101.1| Ycf2 [Arabidopsis thaliana]'\n",
      "        >>> records[\"45478717\"].description\n",
      "        'gi|45478717|ref|NP_995572.1| pesticin [Yersinia pestis biovar Microtus str. 91001]'\n",
      "        >>> records.close()\n",
      "        \n",
      "        In this example the two files contain 85 and 10 records respectively.\n",
      "        \n",
      "        BGZF compressed files are supported, and detected automatically. Ordinary\n",
      "        GZIP compressed files are not supported.\n",
      "        \n",
      "        See Also: Bio.SeqIO.index() and Bio.SeqIO.to_dict(), and the Python module\n",
      "        glob which is useful for building lists of files.\n",
      "    \n",
      "    parse(handle, format, alphabet=None)\n",
      "        Turn a sequence file into an iterator returning SeqRecords.\n",
      "        \n",
      "        Arguments:\n",
      "         - handle   - handle to the file, or the filename as a string\n",
      "           (note older versions of Biopython only took a handle).\n",
      "         - format   - lower case string describing the file format.\n",
      "         - alphabet - no longer used, should be None.\n",
      "        \n",
      "        Typical usage, opening a file to read in, and looping over the record(s):\n",
      "        \n",
      "        >>> from Bio import SeqIO\n",
      "        >>> filename = \"Fasta/sweetpea.nu\"\n",
      "        >>> for record in SeqIO.parse(filename, \"fasta\"):\n",
      "        ...    print(\"ID %s\" % record.id)\n",
      "        ...    print(\"Sequence length %i\" % len(record))\n",
      "        ID gi|3176602|gb|U78617.1|LOU78617\n",
      "        Sequence length 309\n",
      "        \n",
      "        For lazy-loading file formats such as twobit, for which the file contents\n",
      "        is read on demand only, ensure that the file remains open while extracting\n",
      "        sequence data.\n",
      "        \n",
      "        If you have a string 'data' containing the file contents, you must\n",
      "        first turn this into a handle in order to parse it:\n",
      "        \n",
      "        >>> data = \">Alpha\\nACCGGATGTA\\n>Beta\\nAGGCTCGGTTA\\n\"\n",
      "        >>> from Bio import SeqIO\n",
      "        >>> from io import StringIO\n",
      "        >>> for record in SeqIO.parse(StringIO(data), \"fasta\"):\n",
      "        ...     print(\"%s %s\" % (record.id, record.seq))\n",
      "        Alpha ACCGGATGTA\n",
      "        Beta AGGCTCGGTTA\n",
      "        \n",
      "        Use the Bio.SeqIO.read(...) function when you expect a single record\n",
      "        only.\n",
      "    \n",
      "    read(handle, format, alphabet=None)\n",
      "        Turn a sequence file into a single SeqRecord.\n",
      "        \n",
      "        Arguments:\n",
      "         - handle   - handle to the file, or the filename as a string\n",
      "           (note older versions of Biopython only took a handle).\n",
      "         - format   - string describing the file format.\n",
      "         - alphabet - no longer used, should be None.\n",
      "        \n",
      "        This function is for use parsing sequence files containing\n",
      "        exactly one record.  For example, reading a GenBank file:\n",
      "        \n",
      "        >>> from Bio import SeqIO\n",
      "        >>> record = SeqIO.read(\"GenBank/arab1.gb\", \"genbank\")\n",
      "        >>> print(\"ID %s\" % record.id)\n",
      "        ID AC007323.5\n",
      "        >>> print(\"Sequence length %i\" % len(record))\n",
      "        Sequence length 86436\n",
      "        \n",
      "        If the handle contains no records, or more than one record,\n",
      "        an exception is raised.  For example:\n",
      "        \n",
      "        >>> from Bio import SeqIO\n",
      "        >>> record = SeqIO.read(\"GenBank/cor6_6.gb\", \"genbank\")\n",
      "        Traceback (most recent call last):\n",
      "            ...\n",
      "        ValueError: More than one record found in handle\n",
      "        \n",
      "        If however you want the first record from a file containing\n",
      "        multiple records this function would raise an exception (as\n",
      "        shown in the example above).  Instead use:\n",
      "        \n",
      "        >>> from Bio import SeqIO\n",
      "        >>> record = next(SeqIO.parse(\"GenBank/cor6_6.gb\", \"genbank\"))\n",
      "        >>> print(\"First record's ID %s\" % record.id)\n",
      "        First record's ID X55053.1\n",
      "        \n",
      "        Use the Bio.SeqIO.parse(handle, format) function if you want\n",
      "        to read multiple records from the handle.\n",
      "    \n",
      "    to_dict(sequences, key_function=None)\n",
      "        Turn a sequence iterator or list into a dictionary.\n",
      "        \n",
      "        Arguments:\n",
      "         - sequences  - An iterator that returns SeqRecord objects,\n",
      "           or simply a list of SeqRecord objects.\n",
      "         - key_function - Optional callback function which when given a\n",
      "           SeqRecord should return a unique key for the dictionary.\n",
      "        \n",
      "        e.g. key_function = lambda rec : rec.name\n",
      "        or,  key_function = lambda rec : rec.description.split()[0]\n",
      "        \n",
      "        If key_function is omitted then record.id is used, on the assumption\n",
      "        that the records objects returned are SeqRecords with a unique id.\n",
      "        \n",
      "        If there are duplicate keys, an error is raised.\n",
      "        \n",
      "        Since Python 3.7, the default dict class maintains key order, meaning\n",
      "        this dictionary will reflect the order of records given to it. For\n",
      "        CPython and PyPy, this was already implemented for Python 3.6, so\n",
      "        effectively you can always assume the record order is preserved.\n",
      "        \n",
      "        Example usage, defaulting to using the record.id as key:\n",
      "        \n",
      "        >>> from Bio import SeqIO\n",
      "        >>> filename = \"GenBank/cor6_6.gb\"\n",
      "        >>> format = \"genbank\"\n",
      "        >>> id_dict = SeqIO.to_dict(SeqIO.parse(filename, format))\n",
      "        >>> print(list(id_dict))\n",
      "        ['X55053.1', 'X62281.1', 'M81224.1', 'AJ237582.1', 'L31939.1', 'AF297471.1']\n",
      "        >>> print(id_dict[\"L31939.1\"].description)\n",
      "        Brassica rapa (clone bif72) kin mRNA, complete cds\n",
      "        \n",
      "        A more complex example, using the key_function argument in order to\n",
      "        use a sequence checksum as the dictionary key:\n",
      "        \n",
      "        >>> from Bio import SeqIO\n",
      "        >>> from Bio.SeqUtils.CheckSum import seguid\n",
      "        >>> filename = \"GenBank/cor6_6.gb\"\n",
      "        >>> format = \"genbank\"\n",
      "        >>> seguid_dict = SeqIO.to_dict(SeqIO.parse(filename, format),\n",
      "        ...               key_function = lambda rec : seguid(rec.seq))\n",
      "        >>> for key, record in sorted(seguid_dict.items()):\n",
      "        ...     print(\"%s %s\" % (key, record.id))\n",
      "        /wQvmrl87QWcm9llO4/efg23Vgg AJ237582.1\n",
      "        BUg6YxXSKWEcFFH0L08JzaLGhQs L31939.1\n",
      "        SabZaA4V2eLE9/2Fm5FnyYy07J4 X55053.1\n",
      "        TtWsXo45S3ZclIBy4X/WJc39+CY M81224.1\n",
      "        l7gjJFE6W/S1jJn5+1ASrUKW/FA X62281.1\n",
      "        uVEYeAQSV5EDQOnFoeMmVea+Oow AF297471.1\n",
      "        \n",
      "        This approach is not suitable for very large sets of sequences, as all\n",
      "        the SeqRecord objects are held in memory. Instead, consider using the\n",
      "        Bio.SeqIO.index() function (if it supports your particular file format).\n",
      "        \n",
      "        Since Python 3.6, the default dict class maintains key order, meaning\n",
      "        this dictionary will reflect the order of records given to it. As of\n",
      "        Biopython 1.72, on older versions of Python we explicitly use an\n",
      "        OrderedDict so that you can always assume the record order is preserved.\n",
      "    \n",
      "    write(sequences, handle, format)\n",
      "        Write complete set of sequences to a file.\n",
      "        \n",
      "        Arguments:\n",
      "         - sequences - A list (or iterator) of SeqRecord objects, or a single\n",
      "           SeqRecord.\n",
      "         - handle    - File handle object to write to, or filename as string.\n",
      "         - format    - lower case string describing the file format to write.\n",
      "        \n",
      "        Note if providing a file handle, your code should close the handle\n",
      "        after calling this function (to ensure the data gets flushed to disk).\n",
      "        \n",
      "        Returns the number of records written (as an integer).\n",
      "\n",
      "FILE\n",
      "    c:\\users\\shatadru das\\anaconda3\\lib\\site-packages\\bio\\seqio\\__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "help(SeqIO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The “catch” is that you have to work with SeqRecord objects (see Chapter ‍4), which contain a Seq object (see Chapter ‍3) plus annotation like an identifier and description. Note that when dealing with very large FASTA or FASTQ files, the overhead of working with all these objects can make scripts too slow. In this case consider the low-level SimpleFastaParser and FastqGeneralIterator parsers which return just a tuple of strings for each record (see Section ‍5.6)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Parsing or Reading Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The workhorse function `Bio.SeqIO.parse()` is used to read in sequence data as SeqRecord objects. This function expects two arguments:\n",
    "\n",
    "1. The first argument is a handle to read the data from, or a filename. A handle is typically a file opened for reading, but could be the output from a command line program, or data downloaded from the internet (see Section ‍5.3). See Section ‍24.1 for more about handles.\n",
    "   \n",
    "2. The second argument is a lower case string specifying sequence format – we don’t try and guess the file format for you! See http://biopython.org/wiki/SeqIO for a full listing of supported formats.\n",
    "\n",
    "The `Bio.SeqIO.parse()` function returns an iterator which gives SeqRecord objects. Iterators are typically used in a for loop as shown below.\n",
    "\n",
    "Sometimes you’ll find yourself dealing with files which contain only a single record. For this situation use the function `Bio.SeqIO.read()` which takes the same arguments. Provided there is one and only one record in the file, this is returned as a SeqRecord object. Otherwise an exception is raised."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.1 Reading Sequence Files\n",
    "In general Bio.SeqIO.parse() is used to read in sequence files as SeqRecord objects, and is typically used with a for loop like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gi|2765658|emb|Z78533.1|CIZ78533\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGATGAGACCGTGG...CGC')\n",
      "740\n",
      "gi|2765657|emb|Z78532.1|CCZ78532\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGACAACAG...GGC')\n",
      "753\n",
      "gi|2765656|emb|Z78531.1|CFZ78531\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGACAGCAG...TAA')\n",
      "748\n",
      "gi|2765655|emb|Z78530.1|CMZ78530\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAAACAACAT...CAT')\n",
      "744\n",
      "gi|2765654|emb|Z78529.1|CLZ78529\n",
      "Seq('ACGGCGAGCTGCCGAAGGACATTGTTGAGACAGCAGAATATACGATTGAGTGAA...AAA')\n",
      "733\n",
      "gi|2765652|emb|Z78527.1|CYZ78527\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGACAGTAG...CCC')\n",
      "718\n",
      "gi|2765651|emb|Z78526.1|CGZ78526\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGACAGTAG...TGT')\n",
      "730\n",
      "gi|2765650|emb|Z78525.1|CAZ78525\n",
      "Seq('TGTTGAGATAGCAGAATATACATCGAGTGAATCCGGAGGACCTGTGGTTATTCG...GCA')\n",
      "704\n",
      "gi|2765649|emb|Z78524.1|CFZ78524\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATAGTAG...AGC')\n",
      "740\n",
      "gi|2765648|emb|Z78523.1|CHZ78523\n",
      "Seq('CGTAACCAGGTTTCCGTAGGTGAACCTGCGGCAGGATCATTGTTGAGACAGCAG...AAG')\n",
      "709\n",
      "gi|2765647|emb|Z78522.1|CMZ78522\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGACAGCAG...GAG')\n",
      "700\n",
      "gi|2765646|emb|Z78521.1|CCZ78521\n",
      "Seq('GTAGGTGAACCTGCGGAAGGATCATTGTTGAGACAGTAGAATATATGATCGAGT...ACC')\n",
      "726\n",
      "gi|2765645|emb|Z78520.1|CSZ78520\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGACAGCAG...TTT')\n",
      "753\n",
      "gi|2765644|emb|Z78519.1|CPZ78519\n",
      "Seq('ATATGATCGAGTGAATCTGGTGGACTTGTGGTTACTCAGCTCGCCATAGGCTTT...TTA')\n",
      "699\n",
      "gi|2765643|emb|Z78518.1|CRZ78518\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGGAGGATCATTGTTGAGATAGTAG...TCC')\n",
      "658\n",
      "gi|2765642|emb|Z78517.1|CFZ78517\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGACAGTAG...AGC')\n",
      "752\n",
      "gi|2765641|emb|Z78516.1|CPZ78516\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGACAGTAT...TAA')\n",
      "726\n",
      "gi|2765640|emb|Z78515.1|MXZ78515\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGCTGAGACCGTAG...AGC')\n",
      "765\n",
      "gi|2765639|emb|Z78514.1|PSZ78514\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGGACCTTCGGGAGGATCATTTTTGAAGCCCCCA...CTA')\n",
      "755\n",
      "gi|2765638|emb|Z78513.1|PBZ78513\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGACCGCCA...GAG')\n",
      "742\n",
      "gi|2765637|emb|Z78512.1|PWZ78512\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGGACCTTCGGGAGGATCATTTTTGAAGCCCCCA...AGC')\n",
      "762\n",
      "gi|2765636|emb|Z78511.1|PEZ78511\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTTCGGAAGGATCATTGTTGAGACCCCCA...GGA')\n",
      "745\n",
      "gi|2765635|emb|Z78510.1|PCZ78510\n",
      "Seq('CTAACCAGGGTTCCGAGGTGACCTTCGGGAGGATTCCTTTTTAAGCCCCCGAAA...TTA')\n",
      "750\n",
      "gi|2765634|emb|Z78509.1|PPZ78509\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGACCGCCA...GGA')\n",
      "731\n",
      "gi|2765633|emb|Z78508.1|PLZ78508\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGACCGCCA...TGA')\n",
      "741\n",
      "gi|2765632|emb|Z78507.1|PLZ78507\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGACCCCCA...TGA')\n",
      "740\n",
      "gi|2765631|emb|Z78506.1|PLZ78506\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGACCGCAA...TGA')\n",
      "727\n",
      "gi|2765630|emb|Z78505.1|PSZ78505\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGACCGCCA...TTT')\n",
      "711\n",
      "gi|2765629|emb|Z78504.1|PKZ78504\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTTCGGAAGGATCATTGTTGAGACCGCAA...TAA')\n",
      "743\n",
      "gi|2765628|emb|Z78503.1|PCZ78503\n",
      "Seq('CGTAACCAGGTTTCCGTAGGTGAACCTCCGGAAGGATCCTTGTTGAGACCGCCA...TAA')\n",
      "727\n",
      "gi|2765627|emb|Z78502.1|PBZ78502\n",
      "Seq('CGTAACCAGGTTTCCGTAGGTGAACCTCCGGAAGGATCATTGTTGAGACCGCCA...CGC')\n",
      "757\n",
      "gi|2765626|emb|Z78501.1|PCZ78501\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGACCGCAA...AGA')\n",
      "770\n",
      "gi|2765625|emb|Z78500.1|PWZ78500\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGCTCATTGTTGAGACCGCAA...AAG')\n",
      "767\n",
      "gi|2765624|emb|Z78499.1|PMZ78499\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAGGGATCATTGTTGAGATCGCAT...ACC')\n",
      "759\n",
      "gi|2765623|emb|Z78498.1|PMZ78498\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAAGGTCATTGTTGAGATCACAT...AGC')\n",
      "750\n",
      "gi|2765622|emb|Z78497.1|PDZ78497\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCACAT...AGC')\n",
      "788\n",
      "gi|2765621|emb|Z78496.1|PAZ78496\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCGCAT...AGC')\n",
      "774\n",
      "gi|2765620|emb|Z78495.1|PEZ78495\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTCCGGAAGGATCATTGTTGAGATCACAT...GTG')\n",
      "789\n",
      "gi|2765619|emb|Z78494.1|PNZ78494\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGGTCGCAT...AAG')\n",
      "688\n",
      "gi|2765618|emb|Z78493.1|PGZ78493\n",
      "Seq('CGTAACAAGGATTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCGCAT...CCC')\n",
      "719\n",
      "gi|2765617|emb|Z78492.1|PBZ78492\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCGCAT...ATA')\n",
      "743\n",
      "gi|2765616|emb|Z78491.1|PCZ78491\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCGCAT...AGC')\n",
      "737\n",
      "gi|2765615|emb|Z78490.1|PFZ78490\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCACAT...TGA')\n",
      "728\n",
      "gi|2765614|emb|Z78489.1|PDZ78489\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCACAT...GGC')\n",
      "740\n",
      "gi|2765613|emb|Z78488.1|PTZ78488\n",
      "Seq('CTGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCACGCAATAATTGATCGA...GCT')\n",
      "696\n",
      "gi|2765612|emb|Z78487.1|PHZ78487\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCACAT...TAA')\n",
      "732\n",
      "gi|2765611|emb|Z78486.1|PBZ78486\n",
      "Seq('CGTCACGAGGTTTCCGTAGGTGAATCTGCGGGAGGATCATTGTTGAGATCACAT...TGA')\n",
      "731\n",
      "gi|2765610|emb|Z78485.1|PHZ78485\n",
      "Seq('CTGAACCTGGTGTCCGAAGGTGAATCTGCGGATGGATCATTGTTGAGATATCAT...GTA')\n",
      "735\n",
      "gi|2765609|emb|Z78484.1|PCZ78484\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGGGGAAGGATCATTGTTGAGATCACAT...TTT')\n",
      "720\n",
      "gi|2765608|emb|Z78483.1|PVZ78483\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCACAT...GCA')\n",
      "740\n",
      "gi|2765607|emb|Z78482.1|PEZ78482\n",
      "Seq('TCTACTGCAGTGACCGAGATTTGCCATCGAGCCTCCTGGGAGCTTTCTTGCTGG...GCA')\n",
      "629\n",
      "gi|2765606|emb|Z78481.1|PIZ78481\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCACAT...TGA')\n",
      "572\n",
      "gi|2765605|emb|Z78480.1|PGZ78480\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCACAT...TGA')\n",
      "587\n",
      "gi|2765604|emb|Z78479.1|PPZ78479\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCACAT...AGT')\n",
      "700\n",
      "gi|2765603|emb|Z78478.1|PVZ78478\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTCCGGAAGGATCAGTGTTGAGATCACAT...GGC')\n",
      "636\n",
      "gi|2765602|emb|Z78477.1|PVZ78477\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCACAT...TGC')\n",
      "716\n",
      "gi|2765601|emb|Z78476.1|PGZ78476\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCACAT...CCC')\n",
      "592\n",
      "gi|2765600|emb|Z78475.1|PSZ78475\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCACAT...GGT')\n",
      "716\n",
      "gi|2765599|emb|Z78474.1|PKZ78474\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCACGT...CTT')\n",
      "733\n",
      "gi|2765598|emb|Z78473.1|PSZ78473\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCACAT...AGG')\n",
      "626\n",
      "gi|2765597|emb|Z78472.1|PLZ78472\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCACAT...AGC')\n",
      "737\n",
      "gi|2765596|emb|Z78471.1|PDZ78471\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCACAT...AGC')\n",
      "740\n",
      "gi|2765595|emb|Z78470.1|PPZ78470\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCACAT...GTT')\n",
      "574\n",
      "gi|2765594|emb|Z78469.1|PHZ78469\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCACAT...GTT')\n",
      "594\n",
      "gi|2765593|emb|Z78468.1|PAZ78468\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCGCAT...GTT')\n",
      "610\n",
      "gi|2765592|emb|Z78467.1|PSZ78467\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCACAT...TGA')\n",
      "730\n",
      "gi|2765591|emb|Z78466.1|PPZ78466\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCACAT...CCC')\n",
      "641\n",
      "gi|2765590|emb|Z78465.1|PRZ78465\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCACAT...TGC')\n",
      "702\n",
      "gi|2765589|emb|Z78464.1|PGZ78464\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAGCGGAAGGGTCATTGTTGAGATCACATAATA...AGC')\n",
      "733\n",
      "gi|2765588|emb|Z78463.1|PGZ78463\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGTTCATTGTTGAGATCACAT...AGC')\n",
      "738\n",
      "gi|2765587|emb|Z78462.1|PSZ78462\n",
      "Seq('CGTCACGAGGTCTCCGGATGTGACCCTGCGGAAGGATCATTGTTGAGATCACAT...CAT')\n",
      "736\n",
      "gi|2765586|emb|Z78461.1|PWZ78461\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTCCGGAAGGATCATTGTTGAGATCACAT...TAA')\n",
      "732\n",
      "gi|2765585|emb|Z78460.1|PCZ78460\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTCCGGAAGGATCATTGTTGAGATCACAT...TTA')\n",
      "745\n",
      "gi|2765584|emb|Z78459.1|PDZ78459\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCACAT...TTT')\n",
      "744\n",
      "gi|2765583|emb|Z78458.1|PHZ78458\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCACAT...TTG')\n",
      "738\n",
      "gi|2765582|emb|Z78457.1|PCZ78457\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTCCGGAAGGATCATTGTTGAGATCACAT...GAG')\n",
      "739\n",
      "gi|2765581|emb|Z78456.1|PTZ78456\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCACAT...AGC')\n",
      "740\n",
      "gi|2765580|emb|Z78455.1|PJZ78455\n",
      "Seq('CGTAACCAGGTTTCCGTAGGTGGACCTTCGGGAGGATCATTTTTGAGATCACAT...GCA')\n",
      "745\n",
      "gi|2765579|emb|Z78454.1|PFZ78454\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCACAT...AAC')\n",
      "695\n",
      "gi|2765578|emb|Z78453.1|PSZ78453\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCACAT...GCA')\n",
      "745\n",
      "gi|2765577|emb|Z78452.1|PBZ78452\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCACAT...GCA')\n",
      "743\n",
      "gi|2765576|emb|Z78451.1|PHZ78451\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGTACCTCCGGAAGGATCATTGTTGAGATCACAT...AGC')\n",
      "730\n",
      "gi|2765575|emb|Z78450.1|PPZ78450\n",
      "Seq('GGAAGGATCATTGCTGATATCACATAATAATTGATCGAGTTAAGCTGGAGGATC...GAG')\n",
      "706\n",
      "gi|2765574|emb|Z78449.1|PMZ78449\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCACAT...TGC')\n",
      "744\n",
      "gi|2765573|emb|Z78448.1|PAZ78448\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCACAT...AGG')\n",
      "742\n",
      "gi|2765572|emb|Z78447.1|PVZ78447\n",
      "Seq('CGTAACAAGGATTCCGTAGGTGAACCTGCGGGAGGATCATTGTTGAGATCACAT...AGC')\n",
      "694\n",
      "gi|2765571|emb|Z78446.1|PAZ78446\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTCCGGAAGGATCATTGTTGAGATCACAT...CCC')\n",
      "712\n",
      "gi|2765570|emb|Z78445.1|PUZ78445\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCACAT...TGT')\n",
      "715\n",
      "gi|2765569|emb|Z78444.1|PAZ78444\n",
      "Seq('CGTAACAAGGTTTCCGTAGGGTGAACTGCGGAAGGATCATTGTTGAGATCACAT...ATT')\n",
      "688\n",
      "gi|2765568|emb|Z78443.1|PLZ78443\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCACAT...AGG')\n",
      "784\n",
      "gi|2765567|emb|Z78442.1|PBZ78442\n",
      "Seq('GTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCACATAATAATTGATCGAGT...AGT')\n",
      "721\n",
      "gi|2765566|emb|Z78441.1|PSZ78441\n",
      "Seq('GGAAGGTCATTGCCGATATCACATAATAATTGATCGAGTTAATCTGGAGGATCT...GAG')\n",
      "703\n",
      "gi|2765565|emb|Z78440.1|PPZ78440\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGGACCTCCGGGAGGATCATTGTTGAGATCACAT...GCA')\n",
      "744\n",
      "gi|2765564|emb|Z78439.1|PBZ78439\n",
      "Seq('CATTGTTGAGATCACATAATAATTGATCGAGTTAATCTGGAGGATCTGTTTACT...GCC')\n",
      "592\n"
     ]
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "_path = \"data/\"\n",
    "for seq_record in SeqIO.parse(_path + \"ls_orchid.fasta\", \"fasta\"):\n",
    "    print(seq_record.id)\n",
    "    print(repr(seq_record.seq))\n",
    "    print(len(seq_record))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The above example is repeated from the introduction in Section ‍2.4, and will load the orchid DNA sequences in the FASTA format file ls_orchid.fasta. If instead you wanted to load a GenBank format file like ls_orchid.gbk then all you need to do is change the filename and the format string:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z78533.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGATGAGACCGTGG...CGC')\n",
      "740\n",
      "Z78532.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGACAACAG...GGC')\n",
      "753\n",
      "Z78531.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGACAGCAG...TAA')\n",
      "748\n",
      "Z78530.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAAACAACAT...CAT')\n",
      "744\n",
      "Z78529.1\n",
      "Seq('ACGGCGAGCTGCCGAAGGACATTGTTGAGACAGCAGAATATACGATTGAGTGAA...AAA')\n",
      "733\n",
      "Z78527.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGACAGTAG...CCC')\n",
      "718\n",
      "Z78526.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGACAGTAG...TGT')\n",
      "730\n",
      "Z78525.1\n",
      "Seq('TGTTGAGATAGCAGAATATACATCGAGTGAATCCGGAGGACCTGTGGTTATTCG...GCA')\n",
      "704\n",
      "Z78524.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATAGTAG...AGC')\n",
      "740\n",
      "Z78523.1\n",
      "Seq('CGTAACCAGGTTTCCGTAGGTGAACCTGCGGCAGGATCATTGTTGAGACAGCAG...AAG')\n",
      "709\n",
      "Z78522.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGACAGCAG...GAG')\n",
      "700\n",
      "Z78521.1\n",
      "Seq('GTAGGTGAACCTGCGGAAGGATCATTGTTGAGACAGTAGAATATATGATCGAGT...ACC')\n",
      "726\n",
      "Z78520.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGACAGCAG...TTT')\n",
      "753\n",
      "Z78519.1\n",
      "Seq('ATATGATCGAGTGAATCTGGTGGACTTGTGGTTACTCAGCTCGCCATAGGCTTT...TTA')\n",
      "699\n",
      "Z78518.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGGAGGATCATTGTTGAGATAGTAG...TCC')\n",
      "658\n",
      "Z78517.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGACAGTAG...AGC')\n",
      "752\n",
      "Z78516.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGACAGTAT...TAA')\n",
      "726\n",
      "Z78515.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGCTGAGACCGTAG...AGC')\n",
      "765\n",
      "Z78514.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGGACCTTCGGGAGGATCATTTTTGAAGCCCCCA...CTA')\n",
      "755\n",
      "Z78513.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGACCGCCA...GAG')\n",
      "742\n",
      "Z78512.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGGACCTTCGGGAGGATCATTTTTGAAGCCCCCA...AGC')\n",
      "762\n",
      "Z78511.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTTCGGAAGGATCATTGTTGAGACCCCCA...GGA')\n",
      "745\n",
      "Z78510.1\n",
      "Seq('CTAACCAGGGTTCCGAGGTGACCTTCGGGAGGATTCCTTTTTAAGCCCCCGAAA...TTA')\n",
      "750\n",
      "Z78509.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGACCGCCA...GGA')\n",
      "731\n",
      "Z78508.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGACCGCCA...TGA')\n",
      "741\n",
      "Z78507.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGACCCCCA...TGA')\n",
      "740\n",
      "Z78506.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGACCGCAA...TGA')\n",
      "727\n",
      "Z78505.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGACCGCCA...TTT')\n",
      "711\n",
      "Z78504.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTTCGGAAGGATCATTGTTGAGACCGCAA...TAA')\n",
      "743\n",
      "Z78503.1\n",
      "Seq('CGTAACCAGGTTTCCGTAGGTGAACCTCCGGAAGGATCCTTGTTGAGACCGCCA...TAA')\n",
      "727\n",
      "Z78502.1\n",
      "Seq('CGTAACCAGGTTTCCGTAGGTGAACCTCCGGAAGGATCATTGTTGAGACCGCCA...CGC')\n",
      "757\n",
      "Z78501.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGACCGCAA...AGA')\n",
      "770\n",
      "Z78500.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGCTCATTGTTGAGACCGCAA...AAG')\n",
      "767\n",
      "Z78499.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAGGGATCATTGTTGAGATCGCAT...ACC')\n",
      "759\n",
      "Z78498.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAAGGTCATTGTTGAGATCACAT...AGC')\n",
      "750\n",
      "Z78497.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCACAT...AGC')\n",
      "788\n",
      "Z78496.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCGCAT...AGC')\n",
      "774\n",
      "Z78495.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTCCGGAAGGATCATTGTTGAGATCACAT...GTG')\n",
      "789\n",
      "Z78494.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGGTCGCAT...AAG')\n",
      "688\n",
      "Z78493.1\n",
      "Seq('CGTAACAAGGATTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCGCAT...CCC')\n",
      "719\n",
      "Z78492.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCGCAT...ATA')\n",
      "743\n",
      "Z78491.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCGCAT...AGC')\n",
      "737\n",
      "Z78490.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCACAT...TGA')\n",
      "728\n",
      "Z78489.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCACAT...GGC')\n",
      "740\n",
      "Z78488.1\n",
      "Seq('CTGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCACGCAATAATTGATCGA...GCT')\n",
      "696\n",
      "Z78487.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCACAT...TAA')\n",
      "732\n",
      "Z78486.1\n",
      "Seq('CGTCACGAGGTTTCCGTAGGTGAATCTGCGGGAGGATCATTGTTGAGATCACAT...TGA')\n",
      "731\n",
      "Z78485.1\n",
      "Seq('CTGAACCTGGTGTCCGAAGGTGAATCTGCGGATGGATCATTGTTGAGATATCAT...GTA')\n",
      "735\n",
      "Z78484.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGGGGAAGGATCATTGTTGAGATCACAT...TTT')\n",
      "720\n",
      "Z78483.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCACAT...GCA')\n",
      "740\n",
      "Z78482.1\n",
      "Seq('TCTACTGCAGTGACCGAGATTTGCCATCGAGCCTCCTGGGAGCTTTCTTGCTGG...GCA')\n",
      "629\n",
      "Z78481.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCACAT...TGA')\n",
      "572\n",
      "Z78480.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCACAT...TGA')\n",
      "587\n",
      "Z78479.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCACAT...AGT')\n",
      "700\n",
      "Z78478.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTCCGGAAGGATCAGTGTTGAGATCACAT...GGC')\n",
      "636\n",
      "Z78477.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCACAT...TGC')\n",
      "716\n",
      "Z78476.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCACAT...CCC')\n",
      "592\n",
      "Z78475.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCACAT...GGT')\n",
      "716\n",
      "Z78474.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCACGT...CTT')\n",
      "733\n",
      "Z78473.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCACAT...AGG')\n",
      "626\n",
      "Z78472.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCACAT...AGC')\n",
      "737\n",
      "Z78471.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCACAT...AGC')\n",
      "740\n",
      "Z78470.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCACAT...GTT')\n",
      "574\n",
      "Z78469.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCACAT...GTT')\n",
      "594\n",
      "Z78468.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCGCAT...GTT')\n",
      "610\n",
      "Z78467.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCACAT...TGA')\n",
      "730\n",
      "Z78466.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCACAT...CCC')\n",
      "641\n",
      "Z78465.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCACAT...TGC')\n",
      "702\n",
      "Z78464.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAGCGGAAGGGTCATTGTTGAGATCACATAATA...AGC')\n",
      "733\n",
      "Z78463.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGTTCATTGTTGAGATCACAT...AGC')\n",
      "738\n",
      "Z78462.1\n",
      "Seq('CGTCACGAGGTCTCCGGATGTGACCCTGCGGAAGGATCATTGTTGAGATCACAT...CAT')\n",
      "736\n",
      "Z78461.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTCCGGAAGGATCATTGTTGAGATCACAT...TAA')\n",
      "732\n",
      "Z78460.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTCCGGAAGGATCATTGTTGAGATCACAT...TTA')\n",
      "745\n",
      "Z78459.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCACAT...TTT')\n",
      "744\n",
      "Z78458.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCACAT...TTG')\n",
      "738\n",
      "Z78457.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTCCGGAAGGATCATTGTTGAGATCACAT...GAG')\n",
      "739\n",
      "Z78456.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCACAT...AGC')\n",
      "740\n",
      "Z78455.1\n",
      "Seq('CGTAACCAGGTTTCCGTAGGTGGACCTTCGGGAGGATCATTTTTGAGATCACAT...GCA')\n",
      "745\n",
      "Z78454.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCACAT...AAC')\n",
      "695\n",
      "Z78453.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCACAT...GCA')\n",
      "745\n",
      "Z78452.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCACAT...GCA')\n",
      "743\n",
      "Z78451.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGTACCTCCGGAAGGATCATTGTTGAGATCACAT...AGC')\n",
      "730\n",
      "Z78450.1\n",
      "Seq('GGAAGGATCATTGCTGATATCACATAATAATTGATCGAGTTAAGCTGGAGGATC...GAG')\n",
      "706\n",
      "Z78449.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCACAT...TGC')\n",
      "744\n",
      "Z78448.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCACAT...AGG')\n",
      "742\n",
      "Z78447.1\n",
      "Seq('CGTAACAAGGATTCCGTAGGTGAACCTGCGGGAGGATCATTGTTGAGATCACAT...AGC')\n",
      "694\n",
      "Z78446.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTCCGGAAGGATCATTGTTGAGATCACAT...CCC')\n",
      "712\n",
      "Z78445.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCACAT...TGT')\n",
      "715\n",
      "Z78444.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGGTGAACTGCGGAAGGATCATTGTTGAGATCACAT...ATT')\n",
      "688\n",
      "Z78443.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCACAT...AGG')\n",
      "784\n",
      "Z78442.1\n",
      "Seq('GTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCACATAATAATTGATCGAGT...AGT')\n",
      "721\n",
      "Z78441.1\n",
      "Seq('GGAAGGTCATTGCCGATATCACATAATAATTGATCGAGTTAATCTGGAGGATCT...GAG')\n",
      "703\n",
      "Z78440.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGGACCTCCGGGAGGATCATTGTTGAGATCACAT...GCA')\n",
      "744\n",
      "Z78439.1\n",
      "Seq('CATTGTTGAGATCACATAATAATTGATCGAGTTAATCTGGAGGATCTGTTTACT...GCC')\n",
      "592\n"
     ]
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "for seq_record in SeqIO.parse(_path + \"ls_orchid.gbk\", \"genbank\"):\n",
    "    print(seq_record.id)\n",
    "    print(repr(seq_record.seq))\n",
    "    print(len(seq_record))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Similarly, if you wanted to read in a file in another file format, then assuming Bio.SeqIO.parse() supports it you would just need to change the format string as appropriate, for example “swiss” for SwissProt files or “embl” for EMBL text files. There is a full listing on the wiki page (http://biopython.org/wiki/SeqIO) and in the built in documentation (also online)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Another very common way to use a Python iterator is within a `list comprehension` (or a generator expression). For example, if all you wanted to extract from the file was a list of the record identifiers we can easily do this with the following list comprehension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Z78533.1',\n",
       " 'Z78532.1',\n",
       " 'Z78531.1',\n",
       " 'Z78530.1',\n",
       " 'Z78529.1',\n",
       " 'Z78527.1',\n",
       " 'Z78526.1',\n",
       " 'Z78525.1',\n",
       " 'Z78524.1',\n",
       " 'Z78523.1',\n",
       " 'Z78522.1',\n",
       " 'Z78521.1',\n",
       " 'Z78520.1',\n",
       " 'Z78519.1',\n",
       " 'Z78518.1',\n",
       " 'Z78517.1',\n",
       " 'Z78516.1',\n",
       " 'Z78515.1',\n",
       " 'Z78514.1',\n",
       " 'Z78513.1',\n",
       " 'Z78512.1',\n",
       " 'Z78511.1',\n",
       " 'Z78510.1',\n",
       " 'Z78509.1',\n",
       " 'Z78508.1',\n",
       " 'Z78507.1',\n",
       " 'Z78506.1',\n",
       " 'Z78505.1',\n",
       " 'Z78504.1',\n",
       " 'Z78503.1',\n",
       " 'Z78502.1',\n",
       " 'Z78501.1',\n",
       " 'Z78500.1',\n",
       " 'Z78499.1',\n",
       " 'Z78498.1',\n",
       " 'Z78497.1',\n",
       " 'Z78496.1',\n",
       " 'Z78495.1',\n",
       " 'Z78494.1',\n",
       " 'Z78493.1',\n",
       " 'Z78492.1',\n",
       " 'Z78491.1',\n",
       " 'Z78490.1',\n",
       " 'Z78489.1',\n",
       " 'Z78488.1',\n",
       " 'Z78487.1',\n",
       " 'Z78486.1',\n",
       " 'Z78485.1',\n",
       " 'Z78484.1',\n",
       " 'Z78483.1',\n",
       " 'Z78482.1',\n",
       " 'Z78481.1',\n",
       " 'Z78480.1',\n",
       " 'Z78479.1',\n",
       " 'Z78478.1',\n",
       " 'Z78477.1',\n",
       " 'Z78476.1',\n",
       " 'Z78475.1',\n",
       " 'Z78474.1',\n",
       " 'Z78473.1',\n",
       " 'Z78472.1',\n",
       " 'Z78471.1',\n",
       " 'Z78470.1',\n",
       " 'Z78469.1',\n",
       " 'Z78468.1',\n",
       " 'Z78467.1',\n",
       " 'Z78466.1',\n",
       " 'Z78465.1',\n",
       " 'Z78464.1',\n",
       " 'Z78463.1',\n",
       " 'Z78462.1',\n",
       " 'Z78461.1',\n",
       " 'Z78460.1',\n",
       " 'Z78459.1',\n",
       " 'Z78458.1',\n",
       " 'Z78457.1',\n",
       " 'Z78456.1',\n",
       " 'Z78455.1',\n",
       " 'Z78454.1',\n",
       " 'Z78453.1',\n",
       " 'Z78452.1',\n",
       " 'Z78451.1',\n",
       " 'Z78450.1',\n",
       " 'Z78449.1',\n",
       " 'Z78448.1',\n",
       " 'Z78447.1',\n",
       " 'Z78446.1',\n",
       " 'Z78445.1',\n",
       " 'Z78444.1',\n",
       " 'Z78443.1',\n",
       " 'Z78442.1',\n",
       " 'Z78441.1',\n",
       " 'Z78440.1',\n",
       " 'Z78439.1']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "identifiers = [seq_record.id for seq_record in SeqIO.parse(_path + \"ls_orchid.gbk\", \"genbank\")]\n",
    "identifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are more examples using `SeqIO.parse()` in a list comprehension like this in **Section ‍20.2** (e.g. for plotting sequence lengths or GC%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.2 Iterating over the records in a sequence file\n",
    "\n",
    "In the above examples, we have usually used a for loop to iterate over all the records one by one. You can use the for loop with all sorts of Python objects (including lists, tuples and strings) which support the iteration interface.\n",
    "\n",
    "The object returned by Bio.SeqIO is actually an iterator which returns SeqRecord objects. You get to see each record in turn, but once and only once. The plus point is that an iterator can save you memory when dealing with large files.\n",
    "\n",
    "Instead of using a for loop, can also use the next() function on an iterator to step through the entries, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gi|2765658|emb|Z78533.1|CIZ78533\n",
      "gi|2765658|emb|Z78533.1|CIZ78533 C.irapeanum 5.8S rRNA gene and ITS1 and ITS2 DNA\n",
      "gi|2765657|emb|Z78532.1|CCZ78532\n",
      "gi|2765657|emb|Z78532.1|CCZ78532 C.californicum 5.8S rRNA gene and ITS1 and ITS2 DNA\n"
     ]
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "\n",
    "record_iterator = SeqIO.parse(\"ls_orchid.fasta\", \"fasta\")\n",
    "\n",
    "first_record = next(record_iterator)\n",
    "print(first_record.id)\n",
    "print(first_record.description)\n",
    "\n",
    "second_record = next(record_iterator)\n",
    "print(second_record.id)\n",
    "print(second_record.description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note that if you try to use `next()` and there are **no more results**, you’ll get the special StopIteration exception.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SeqRecord(seq=Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGATGAGACCGTGG...CGC'), id='Z78533.1', name='Z78533', description='C.irapeanum 5.8S rRNA gene and ITS1 and ITS2 DNA', dbxrefs=[])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "\n",
    "first_record = next(SeqIO.parse(_path + \"ls_orchid.gbk\", \"genbank\"))\n",
    "first_record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A word of warning here – using the `next()` function like this will silently ignore any additional records in the file. If your files have one and only one record, like some of the online examples later in this chapter, or a GenBank file for a **single chromosome**, then use the new` Bio.SeqIO.read()` function instead. This will check there are no extra unexpected records present."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.3 Getting a list of the records in a sequence file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous section we talked about the fact that `Bio.SeqIO.parse()` gives you a `SeqRecord` iterator, and that you get the records one by one. Very often you need to be able to access the records in any order. The Python list data type is perfect for this, and we can turn the record iterator into a list of SeqRecord objects using the built-in Python function `list()` like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 94 records\n",
      "The last record\n",
      "Z78439.1\n",
      "Seq('CATTGTTGAGATCACATAATAATTGATCGAGTTAATCTGGAGGATCTGTTTACT...GCC')\n",
      "592\n",
      "The first record\n",
      "Z78533.1\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGATGAGACCGTGG...CGC')\n",
      "740\n"
     ]
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "\n",
    "records = list(SeqIO.parse(_path + \"ls_orchid.gbk\", \"genbank\"))\n",
    "\n",
    "print(\"Found %i records\" % len(records))\n",
    "\n",
    "print(\"The last record\")\n",
    "last_record = records[-1]  # using Python's list tricks\n",
    "print(last_record.id)\n",
    "print(repr(last_record.seq))\n",
    "print(len(last_record))\n",
    "\n",
    "print(\"The first record\")\n",
    "first_record = records[0]  # remember, Python counts from zero\n",
    "print(first_record.id)\n",
    "print(repr(first_record.seq))\n",
    "print(len(first_record))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.4 Extracting data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SeqRecord object and its annotation structures are described more fully in Chapter ‍4. As an example of how annotations are stored, we’ll look at the output from parsing the first record in the GenBank file `ls_orchid.gbk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: Z78533.1\n",
      "Name: Z78533\n",
      "Description: C.irapeanum 5.8S rRNA gene and ITS1 and ITS2 DNA\n",
      "Number of features: 5\n",
      "/molecule_type=DNA\n",
      "/topology=linear\n",
      "/data_file_division=PLN\n",
      "/date=30-NOV-2006\n",
      "/accessions=['Z78533']\n",
      "/sequence_version=1\n",
      "/gi=2765658\n",
      "/keywords=['5.8S ribosomal RNA', '5.8S rRNA gene', 'internal transcribed spacer', 'ITS1', 'ITS2']\n",
      "/source=Cypripedium irapeanum\n",
      "/organism=Cypripedium irapeanum\n",
      "/taxonomy=['Eukaryota', 'Viridiplantae', 'Streptophyta', 'Embryophyta', 'Tracheophyta', 'Spermatophyta', 'Magnoliophyta', 'Liliopsida', 'Asparagales', 'Orchidaceae', 'Cypripedioideae', 'Cypripedium']\n",
      "/references=[Reference(title='Phylogenetics of the slipper orchids (Cypripedioideae: Orchidaceae): nuclear rDNA ITS sequences', ...), Reference(title='Direct Submission', ...)]\n",
      "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGATGAGACCGTGG...CGC')\n"
     ]
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "\n",
    "record_iterator = SeqIO.parse(_path + \"ls_orchid.gbk\", \"genbank\")\n",
    "first_record = next(record_iterator)\n",
    "print(first_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This gives a human readable summary of most of the annotation data for the `SeqRecord`. For this example we’re going to use the .annotations attribute which is just a Python dictionary. The contents of this annotations dictionary were shown when we printed the record above. You can also print them out directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'molecule_type': 'DNA', 'topology': 'linear', 'data_file_division': 'PLN', 'date': '30-NOV-2006', 'accessions': ['Z78533'], 'sequence_version': 1, 'gi': '2765658', 'keywords': ['5.8S ribosomal RNA', '5.8S rRNA gene', 'internal transcribed spacer', 'ITS1', 'ITS2'], 'source': 'Cypripedium irapeanum', 'organism': 'Cypripedium irapeanum', 'taxonomy': ['Eukaryota', 'Viridiplantae', 'Streptophyta', 'Embryophyta', 'Tracheophyta', 'Spermatophyta', 'Magnoliophyta', 'Liliopsida', 'Asparagales', 'Orchidaceae', 'Cypripedioideae', 'Cypripedium'], 'references': [Reference(title='Phylogenetics of the slipper orchids (Cypripedioideae: Orchidaceae): nuclear rDNA ITS sequences', ...), Reference(title='Direct Submission', ...)]}\n"
     ]
    }
   ],
   "source": [
    "print(first_record.annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['molecule_type', 'topology', 'data_file_division', 'date', 'accessions', 'sequence_version', 'gi', 'keywords', 'source', 'organism', 'taxonomy', 'references'])\n",
      "dict_values(['DNA', 'linear', 'PLN', '30-NOV-2006', ['Z78533'], 1, '2765658', ['5.8S ribosomal RNA', '5.8S rRNA gene', 'internal transcribed spacer', 'ITS1', 'ITS2'], 'Cypripedium irapeanum', 'Cypripedium irapeanum', ['Eukaryota', 'Viridiplantae', 'Streptophyta', 'Embryophyta', 'Tracheophyta', 'Spermatophyta', 'Magnoliophyta', 'Liliopsida', 'Asparagales', 'Orchidaceae', 'Cypripedioideae', 'Cypripedium'], [Reference(title='Phylogenetics of the slipper orchids (Cypripedioideae: Orchidaceae): nuclear rDNA ITS sequences', ...), Reference(title='Direct Submission', ...)]])\n"
     ]
    }
   ],
   "source": [
    "# Like any Python dictionary, you can easily get a list of the keys:\n",
    "print(first_record.annotations.keys())\n",
    "\n",
    "## or values:\n",
    "\n",
    "print(first_record.annotations.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, ‘organism’ is used for the scientific name (in Latin, e.g. Arabidopsis thaliana), while ‘source’ will often be the common name (e.g. thale cress). In this example, as is often the case, the two fields are identical.\n",
    "\n",
    "Now let’s go through all the records, building up a list of the species each orchid sequence is from:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cypripedium irapeanum', 'Cypripedium californicum', 'Cypripedium fasciculatum', 'Cypripedium margaritaceum', 'Cypripedium lichiangense', 'Cypripedium yatabeanum', 'Cypripedium guttatum', 'Cypripedium acaule', 'Cypripedium formosanum', 'Cypripedium himalaicum', 'Cypripedium macranthon', 'Cypripedium calceolus', 'Cypripedium segawai', 'Cypripedium parviflorum var. pubescens', 'Cypripedium reginae', 'Cypripedium flavum', 'Cypripedium passerinum', 'Mexipedium xerophyticum', 'Phragmipedium schlimii', 'Phragmipedium besseae', 'Phragmipedium wallisii', 'Phragmipedium exstaminodium', 'Phragmipedium caricinum', 'Phragmipedium pearcei', 'Phragmipedium longifolium', 'Phragmipedium lindenii', 'Phragmipedium lindleyanum', 'Phragmipedium sargentianum', 'Phragmipedium kaiteurum', 'Phragmipedium czerwiakowianum', 'Phragmipedium boissierianum', 'Phragmipedium caudatum', 'Phragmipedium warszewiczianum', 'Paphiopedilum micranthum', 'Paphiopedilum malipoense', 'Paphiopedilum delenatii', 'Paphiopedilum armeniacum', 'Paphiopedilum emersonii', 'Paphiopedilum niveum', 'Paphiopedilum godefroyae', 'Paphiopedilum bellatulum', 'Paphiopedilum concolor', 'Paphiopedilum fairrieanum', 'Paphiopedilum druryi', 'Paphiopedilum tigrinum', 'Paphiopedilum hirsutissimum', 'Paphiopedilum barbigerum', 'Paphiopedilum henryanum', 'Paphiopedilum charlesworthii', 'Paphiopedilum villosum', 'Paphiopedilum exul', 'Paphiopedilum insigne', 'Paphiopedilum gratrixianum', 'Paphiopedilum primulinum', 'Paphiopedilum victoria', 'Paphiopedilum victoria', 'Paphiopedilum glaucophyllum', 'Paphiopedilum supardii', 'Paphiopedilum kolopakingii', 'Paphiopedilum sanderianum', 'Paphiopedilum lowii', 'Paphiopedilum dianthum', 'Paphiopedilum parishii', 'Paphiopedilum haynaldianum', 'Paphiopedilum adductum', 'Paphiopedilum stonei', 'Paphiopedilum philippinense', 'Paphiopedilum rothschildianum', 'Paphiopedilum glanduliferum', 'Paphiopedilum glanduliferum', 'Paphiopedilum sukhakulii', 'Paphiopedilum wardii', 'Paphiopedilum ciliolare', 'Paphiopedilum dayanum', 'Paphiopedilum hennisianum', 'Paphiopedilum callosum', 'Paphiopedilum tonsum', 'Paphiopedilum javanicum', 'Paphiopedilum fowliei', 'Paphiopedilum schoseri', 'Paphiopedilum bougainvilleanum', 'Paphiopedilum hookerae', 'Paphiopedilum papuanum', 'Paphiopedilum mastersianum', 'Paphiopedilum argus', 'Paphiopedilum venustum', 'Paphiopedilum acmodontum', 'Paphiopedilum urbanianum', 'Paphiopedilum appletonianum', 'Paphiopedilum lawrenceanum', 'Paphiopedilum bullenianum', 'Paphiopedilum superbiens', 'Paphiopedilum purpuratum', 'Paphiopedilum barbatum']\n"
     ]
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "\n",
    "all_species = []\n",
    "for seq_record in SeqIO.parse(_path + \"ls_orchid.gbk\", \"genbank\"):\n",
    "    all_species.append(seq_record.annotations[\"organism\"])\n",
    "\n",
    "\n",
    "print(all_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cypripedium irapeanum', 'Cypripedium californicum', 'Cypripedium fasciculatum', 'Cypripedium margaritaceum', 'Cypripedium lichiangense', 'Cypripedium yatabeanum', 'Cypripedium guttatum', 'Cypripedium acaule', 'Cypripedium formosanum', 'Cypripedium himalaicum', 'Cypripedium macranthon', 'Cypripedium calceolus', 'Cypripedium segawai', 'Cypripedium parviflorum var. pubescens', 'Cypripedium reginae', 'Cypripedium flavum', 'Cypripedium passerinum', 'Mexipedium xerophyticum', 'Phragmipedium schlimii', 'Phragmipedium besseae', 'Phragmipedium wallisii', 'Phragmipedium exstaminodium', 'Phragmipedium caricinum', 'Phragmipedium pearcei', 'Phragmipedium longifolium', 'Phragmipedium lindenii', 'Phragmipedium lindleyanum', 'Phragmipedium sargentianum', 'Phragmipedium kaiteurum', 'Phragmipedium czerwiakowianum', 'Phragmipedium boissierianum', 'Phragmipedium caudatum', 'Phragmipedium warszewiczianum', 'Paphiopedilum micranthum', 'Paphiopedilum malipoense', 'Paphiopedilum delenatii', 'Paphiopedilum armeniacum', 'Paphiopedilum emersonii', 'Paphiopedilum niveum', 'Paphiopedilum godefroyae', 'Paphiopedilum bellatulum', 'Paphiopedilum concolor', 'Paphiopedilum fairrieanum', 'Paphiopedilum druryi', 'Paphiopedilum tigrinum', 'Paphiopedilum hirsutissimum', 'Paphiopedilum barbigerum', 'Paphiopedilum henryanum', 'Paphiopedilum charlesworthii', 'Paphiopedilum villosum', 'Paphiopedilum exul', 'Paphiopedilum insigne', 'Paphiopedilum gratrixianum', 'Paphiopedilum primulinum', 'Paphiopedilum victoria', 'Paphiopedilum victoria', 'Paphiopedilum glaucophyllum', 'Paphiopedilum supardii', 'Paphiopedilum kolopakingii', 'Paphiopedilum sanderianum', 'Paphiopedilum lowii', 'Paphiopedilum dianthum', 'Paphiopedilum parishii', 'Paphiopedilum haynaldianum', 'Paphiopedilum adductum', 'Paphiopedilum stonei', 'Paphiopedilum philippinense', 'Paphiopedilum rothschildianum', 'Paphiopedilum glanduliferum', 'Paphiopedilum glanduliferum', 'Paphiopedilum sukhakulii', 'Paphiopedilum wardii', 'Paphiopedilum ciliolare', 'Paphiopedilum dayanum', 'Paphiopedilum hennisianum', 'Paphiopedilum callosum', 'Paphiopedilum tonsum', 'Paphiopedilum javanicum', 'Paphiopedilum fowliei', 'Paphiopedilum schoseri', 'Paphiopedilum bougainvilleanum', 'Paphiopedilum hookerae', 'Paphiopedilum papuanum', 'Paphiopedilum mastersianum', 'Paphiopedilum argus', 'Paphiopedilum venustum', 'Paphiopedilum acmodontum', 'Paphiopedilum urbanianum', 'Paphiopedilum appletonianum', 'Paphiopedilum lawrenceanum', 'Paphiopedilum bullenianum', 'Paphiopedilum superbiens', 'Paphiopedilum purpuratum', 'Paphiopedilum barbatum']\n"
     ]
    }
   ],
   "source": [
    "## Another way of writing this code is to use a list comprehension:\n",
    "\n",
    "from Bio import SeqIO\n",
    "\n",
    "all_species = [\n",
    "    seq_record.annotations[\"organism\"]\n",
    "    for seq_record in SeqIO.parse(_path + \"ls_orchid.gbk\", \"genbank\")\n",
    "]\n",
    "print(all_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cypripedium irapeanum', 'Cypripedium californicum', 'Cypripedium fasciculatum', 'Cypripedium margaritaceum', 'Cypripedium lichiangense', 'Cypripedium yatabeanum', 'Cypripedium guttatum', 'Cypripedium acaule', 'Cypripedium formosanum', 'Cypripedium himalaicum', 'Cypripedium macranthon', 'Cypripedium calceolus', 'Cypripedium segawai', 'Cypripedium parviflorum var. pubescens', 'Cypripedium reginae', 'Cypripedium flavum', 'Cypripedium passerinum', 'Mexipedium xerophyticum', 'Phragmipedium schlimii', 'Phragmipedium besseae', 'Phragmipedium wallisii', 'Phragmipedium exstaminodium', 'Phragmipedium caricinum', 'Phragmipedium pearcei', 'Phragmipedium longifolium', 'Phragmipedium lindenii', 'Phragmipedium lindleyanum', 'Phragmipedium sargentianum', 'Phragmipedium kaiteurum', 'Phragmipedium czerwiakowianum', 'Phragmipedium boissierianum', 'Phragmipedium caudatum', 'Phragmipedium warszewiczianum', 'Paphiopedilum micranthum', 'Paphiopedilum malipoense', 'Paphiopedilum delenatii', 'Paphiopedilum armeniacum', 'Paphiopedilum emersonii', 'Paphiopedilum niveum', 'Paphiopedilum godefroyae', 'Paphiopedilum bellatulum', 'Paphiopedilum concolor', 'Paphiopedilum fairrieanum', 'Paphiopedilum druryi', 'Paphiopedilum tigrinum', 'Paphiopedilum hirsutissimum', 'Paphiopedilum barbigerum', 'Paphiopedilum henryanum', 'Paphiopedilum charlesworthii', 'Paphiopedilum villosum', 'Paphiopedilum exul', 'Paphiopedilum insigne', 'Paphiopedilum gratrixianum', 'Paphiopedilum primulinum', 'Paphiopedilum victoria', 'Paphiopedilum victoria', 'Paphiopedilum glaucophyllum', 'Paphiopedilum supardii', 'Paphiopedilum kolopakingii', 'Paphiopedilum sanderianum', 'Paphiopedilum lowii', 'Paphiopedilum dianthum', 'Paphiopedilum parishii', 'Paphiopedilum haynaldianum', 'Paphiopedilum adductum', 'Paphiopedilum stonei', 'Paphiopedilum philippinense', 'Paphiopedilum rothschildianum', 'Paphiopedilum glanduliferum', 'Paphiopedilum glanduliferum', 'Paphiopedilum sukhakulii', 'Paphiopedilum wardii', 'Paphiopedilum ciliolare', 'Paphiopedilum dayanum', 'Paphiopedilum hennisianum', 'Paphiopedilum callosum', 'Paphiopedilum tonsum', 'Paphiopedilum javanicum', 'Paphiopedilum fowliei', 'Paphiopedilum schoseri', 'Paphiopedilum bougainvilleanum', 'Paphiopedilum hookerae', 'Paphiopedilum papuanum', 'Paphiopedilum mastersianum', 'Paphiopedilum argus', 'Paphiopedilum venustum', 'Paphiopedilum acmodontum', 'Paphiopedilum urbanianum', 'Paphiopedilum appletonianum', 'Paphiopedilum lawrenceanum', 'Paphiopedilum bullenianum', 'Paphiopedilum superbiens', 'Paphiopedilum purpuratum', 'Paphiopedilum barbatum']\n"
     ]
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "\n",
    "all_species = []\n",
    "for seq_record in SeqIO.parse(_path + \"ls_orchid.gbk\", \"genbank\"):\n",
    "    all_species.append(seq_record.annotations[\"organism\"])\n",
    "print(all_species)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cypripedium irapeanum', 'Cypripedium californicum', 'Cypripedium fasciculatum', 'Cypripedium margaritaceum', 'Cypripedium lichiangense', 'Cypripedium yatabeanum', 'Cypripedium guttatum', 'Cypripedium acaule', 'Cypripedium formosanum', 'Cypripedium himalaicum', 'Cypripedium macranthon', 'Cypripedium calceolus', 'Cypripedium segawai', 'Cypripedium parviflorum var. pubescens', 'Cypripedium reginae', 'Cypripedium flavum', 'Cypripedium passerinum', 'Mexipedium xerophyticum', 'Phragmipedium schlimii', 'Phragmipedium besseae', 'Phragmipedium wallisii', 'Phragmipedium exstaminodium', 'Phragmipedium caricinum', 'Phragmipedium pearcei', 'Phragmipedium longifolium', 'Phragmipedium lindenii', 'Phragmipedium lindleyanum', 'Phragmipedium sargentianum', 'Phragmipedium kaiteurum', 'Phragmipedium czerwiakowianum', 'Phragmipedium boissierianum', 'Phragmipedium caudatum', 'Phragmipedium warszewiczianum', 'Paphiopedilum micranthum', 'Paphiopedilum malipoense', 'Paphiopedilum delenatii', 'Paphiopedilum armeniacum', 'Paphiopedilum emersonii', 'Paphiopedilum niveum', 'Paphiopedilum godefroyae', 'Paphiopedilum bellatulum', 'Paphiopedilum concolor', 'Paphiopedilum fairrieanum', 'Paphiopedilum druryi', 'Paphiopedilum tigrinum', 'Paphiopedilum hirsutissimum', 'Paphiopedilum barbigerum', 'Paphiopedilum henryanum', 'Paphiopedilum charlesworthii', 'Paphiopedilum villosum', 'Paphiopedilum exul', 'Paphiopedilum insigne', 'Paphiopedilum gratrixianum', 'Paphiopedilum primulinum', 'Paphiopedilum victoria', 'Paphiopedilum victoria', 'Paphiopedilum glaucophyllum', 'Paphiopedilum supardii', 'Paphiopedilum kolopakingii', 'Paphiopedilum sanderianum', 'Paphiopedilum lowii', 'Paphiopedilum dianthum', 'Paphiopedilum parishii', 'Paphiopedilum haynaldianum', 'Paphiopedilum adductum', 'Paphiopedilum stonei', 'Paphiopedilum philippinense', 'Paphiopedilum rothschildianum', 'Paphiopedilum glanduliferum', 'Paphiopedilum glanduliferum', 'Paphiopedilum sukhakulii', 'Paphiopedilum wardii', 'Paphiopedilum ciliolare', 'Paphiopedilum dayanum', 'Paphiopedilum hennisianum', 'Paphiopedilum callosum', 'Paphiopedilum tonsum', 'Paphiopedilum javanicum', 'Paphiopedilum fowliei', 'Paphiopedilum schoseri', 'Paphiopedilum bougainvilleanum', 'Paphiopedilum hookerae', 'Paphiopedilum papuanum', 'Paphiopedilum mastersianum', 'Paphiopedilum argus', 'Paphiopedilum venustum', 'Paphiopedilum acmodontum', 'Paphiopedilum urbanianum', 'Paphiopedilum appletonianum', 'Paphiopedilum lawrenceanum', 'Paphiopedilum bullenianum', 'Paphiopedilum superbiens', 'Paphiopedilum purpuratum', 'Paphiopedilum barbatum']\n"
     ]
    }
   ],
   "source": [
    "## Another way of writing this code is to use a list comprehension:\n",
    "\n",
    "from Bio import SeqIO\n",
    "\n",
    "all_species = [\n",
    "    seq_record.annotations[\"organism\"]\n",
    "    for seq_record in SeqIO.parse(_path + \"ls_orchid.gbk\", \"genbank\")\n",
    "]\n",
    "print(all_species)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great. That was pretty easy because GenBank files are annotated in a standardised way.\n",
    "\n",
    "Now, let’s suppose you wanted to extract a list of the species from a FASTA file, rather than the GenBank file. The bad news is you will have to write some code to extract the data you want from the record’s description line - if the information is in the file in the first place! Our example FASTA format file ls_orchid.fasta starts like this:\n",
    "\n",
    "```\n",
    ">gi|2765658|emb|Z78533.1|CIZ78533 C.irapeanum 5.8S rRNA gene and ITS1 and ITS2 DNA\n",
    "CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGATGAGACCGTGGAATAAACGATCGAGTG\n",
    "AATCCGGAGGACCGGTGTACTCAGCTCACCGGGGGCATTGCTCCCGTGGTGACCCTGATTTGTTGTTGGG\n",
    "```\n",
    "You can check by hand, but for every record the species name is in the description line as the second word. This means if we break up each record’s .description at the spaces, then the species is there as field number one (field zero is the record identifier). That means we can do this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C.irapeanum', 'C.californicum', 'C.fasciculatum', 'C.margaritaceum', 'C.lichiangense', 'C.yatabeanum', 'C.guttatum', 'C.acaule', 'C.formosanum', 'C.himalaicum', 'C.macranthum', 'C.calceolus', 'C.segawai', 'C.pubescens', 'C.reginae', 'C.flavum', 'C.passerinum', 'M.xerophyticum', 'P.schlimii', 'P.besseae', 'P.wallisii', 'P.exstaminodium', 'P.caricinum', 'P.pearcei', 'P.longifolium', 'P.lindenii', 'P.lindleyanum', 'P.sargentianum', 'P.kaiteurum', 'P.czerwiakowianum', 'P.boissierianum', 'P.caudatum', 'P.warszewiczianum', 'P.micranthum', 'P.malipoense', 'P.delenatii', 'P.armeniacum', 'P.emersonii', 'P.niveum', 'P.godefroyae', 'P.bellatulum', 'P.concolor', 'P.fairrieanum', 'P.druryi', 'P.tigrinum', 'P.hirsutissimum', 'P.barbigerum', 'P.henryanum', 'P.charlesworthii', 'P.villosum', 'P.exul', 'P.insigne', 'P.gratrixianum', 'P.primulinum', 'P.victoria', 'P.victoria', 'P.glaucophyllum', 'P.supardii', 'P.kolopakingii', 'P.sanderianum', 'P.lowii', 'P.dianthum', 'P.parishii', 'P.haynaldianum', 'P.adductum', 'P.stonei', 'P.philippinense', 'P.rothschildianum', 'P.glanduliferum', 'P.glanduliferum', 'P.sukhakulii', 'P.wardii', 'P.ciliolare', 'P.dayanum', 'P.hennisianum', 'P.callosum', 'P.tonsum', 'P.javanicum', 'P.fowliei', 'P.schoseri', 'P.bougainvilleanum', 'P.hookerae', 'P.papuanum', 'P.mastersianum', 'P.argus', 'P.venustum', 'P.acmodontum', 'P.urbanianum', 'P.appletonianum', 'P.lawrenceanum', 'P.bullenianum', 'P.superbiens', 'P.purpuratum', 'P.barbatum']\n"
     ]
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "\n",
    "all_species = []\n",
    "for seq_record in SeqIO.parse(\"ls_orchid.fasta\", \"fasta\"):\n",
    "    all_species.append(seq_record.description.split()[1])\n",
    "print(all_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C.irapeanum', 'C.californicum', 'C.fasciculatum', 'C.margaritaceum', 'C.lichiangense', 'C.yatabeanum', 'C.guttatum', 'C.acaule', 'C.formosanum', 'C.himalaicum', 'C.macranthum', 'C.calceolus', 'C.segawai', 'C.pubescens', 'C.reginae', 'C.flavum', 'C.passerinum', 'M.xerophyticum', 'P.schlimii', 'P.besseae', 'P.wallisii', 'P.exstaminodium', 'P.caricinum', 'P.pearcei', 'P.longifolium', 'P.lindenii', 'P.lindleyanum', 'P.sargentianum', 'P.kaiteurum', 'P.czerwiakowianum', 'P.boissierianum', 'P.caudatum', 'P.warszewiczianum', 'P.micranthum', 'P.malipoense', 'P.delenatii', 'P.armeniacum', 'P.emersonii', 'P.niveum', 'P.godefroyae', 'P.bellatulum', 'P.concolor', 'P.fairrieanum', 'P.druryi', 'P.tigrinum', 'P.hirsutissimum', 'P.barbigerum', 'P.henryanum', 'P.charlesworthii', 'P.villosum', 'P.exul', 'P.insigne', 'P.gratrixianum', 'P.primulinum', 'P.victoria', 'P.victoria', 'P.glaucophyllum', 'P.supardii', 'P.kolopakingii', 'P.sanderianum', 'P.lowii', 'P.dianthum', 'P.parishii', 'P.haynaldianum', 'P.adductum', 'P.stonei', 'P.philippinense', 'P.rothschildianum', 'P.glanduliferum', 'P.glanduliferum', 'P.sukhakulii', 'P.wardii', 'P.ciliolare', 'P.dayanum', 'P.hennisianum', 'P.callosum', 'P.tonsum', 'P.javanicum', 'P.fowliei', 'P.schoseri', 'P.bougainvilleanum', 'P.hookerae', 'P.papuanum', 'P.mastersianum', 'P.argus', 'P.venustum', 'P.acmodontum', 'P.urbanianum', 'P.appletonianum', 'P.lawrenceanum', 'P.bullenianum', 'P.superbiens', 'P.purpuratum', 'P.barbatum']\n"
     ]
    }
   ],
   "source": [
    "## The concise alternative using list comprehensions would be:\n",
    "\n",
    "from Bio import SeqIO\n",
    "\n",
    "all_species == [\n",
    "    seq_record.description.split()[1]\n",
    "    for seq_record in SeqIO.parse(\"ls_orchid.fasta\", \"fasta\")\n",
    "]\n",
    "print(all_species)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, extracting information from the FASTA description line is not very nice. If you can get your sequences in a well annotated file format like GenBank or EMBL, then this sort of annotation information is much easier to deal with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.5 Modifying data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "In the previous section, we demonstrated how to extract data from a SeqRecord. Another common task is to alter this data. The attributes of a SeqRecord can be modified directly, for example:\n",
    "\n",
    "\n",
    "\n",
    "first_record.id = \"new_id\"\n",
    "first_record.id\n",
    "'new_i\n",
    "\n",
    "\n",
    "_id desired new description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gi|2765658|emb|Z78533.1|CIZ78533'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "record_iterator = SeqIO.parse(\"ls_orchid.fasta\", \"fasta\")\n",
    "first_record = next(record_iterator)\n",
    "first_record.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'new_id'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_record.id = \"new_id\"\n",
    "first_record.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, if you want to change the way FASTA is output when written to a file (see Section ‍5.5), then you should modify both the id and description attributes. To ensure the correct behaviour, it is best to include the id plus a space at the start of the desired description:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">new_id desired new description\n",
      "CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGATGAGACCGTGGAATAAA\n",
      "CGATCGAGTGAATCCGGAGGACCGGTGTACTCAGCTCACCGGGGGCATTGCTCCCGTGGT\n",
      "GACCCTGATTTGTTGTTGGGCCGCCTCGGGAGCGTCCATGGCGGGT\n"
     ]
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "record_iterator = SeqIO.parse(_path + \"ls_orchid.fasta\", \"fasta\")\n",
    "first_record = next(record_iterator)\n",
    "first_record.id = \"new_id\"\n",
    "first_record.description = first_record.id + \" \" + \"desired new description\"\n",
    "print(first_record.format(\"fasta\")[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Parsing sequences from compressed files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous section, we looked at parsing sequence data from a file. Instead of using a filename, you can give `Bio.SeqIO` a handle (see Section ‍24.1), and in this section we’ll use handles to parse sequence from compressed files.\n",
    "\n",
    "As you’ll have seen above, we can use `Bio.SeqIO.read()` or `Bio.SeqIO.parse()` with a filename - for instance this quick example calculates the total length of the sequences in a multiple record GenBank file using a generator expression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67518\n"
     ]
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "print(sum(len(r) for r in SeqIO.parse(_path + \"ls_orchid.gbk\", \"gb\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67518\n"
     ]
    }
   ],
   "source": [
    "# Here we use a file handle instead, using the with statement to close the handle automatically:\n",
    "from Bio import SeqIO\n",
    "with open(_path + \"ls_orchid.gbk\") as handle:\n",
    "    print(sum(len(r) for r in SeqIO.parse(handle, \"gb\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67518\n"
     ]
    }
   ],
   "source": [
    "# Or, the old fashioned way where you manually close the handle:\n",
    "from Bio import SeqIO\n",
    "\n",
    "handle = open(_path + \"ls_orchid.gbk\")\n",
    "print(sum(len(r) for r in SeqIO.parse(handle, \"gb\")))\n",
    "handle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, suppose we have a gzip compressed file instead? These are very commonly used on Linux. We can use Python’s gzip module to open the compressed file for reading - which gives us a handle object:\n",
    "\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "with gzip.open(\"ls_orchid.gbk.gz\", \"rt\") as handle:\n",
    "    print(sum(len(r) for r in SeqIO.parse(handle, \"gb\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67518\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "from Bio import SeqIO\n",
    "with gzip.open(_path + \"ls_orchid.gbk.gz\", \"rt\") as handle:\n",
    "    print(sum(len(r) for r in SeqIO.parse(handle, \"gb\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67518\n"
     ]
    }
   ],
   "source": [
    "## Similarly if we had a bzip2 compressed file:\n",
    "import bz2\n",
    "from Bio import SeqIO\n",
    "with bz2.open(_path + \"ls_orchid.gbk.bz2\", \"rt\") as handle:\n",
    "    print(sum(len(r) for r in SeqIO.parse(handle, \"gb\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There is a gzip (GNU Zip) variant called BGZF (Blocked GNU Zip Format), which can be treated like an ordinary gzip file for reading, but has advantages for random access later which we’ll talk about later in **Section ‍5.4.4**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Parsing sequences from the net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous sections, we looked at parsing sequence data from a file (using a filename or handle), and from compressed files (using a handle). Here we’ll use `Bio.SeqIO` with another type of handle, a network connection, to download and parse sequences from the internet.\n",
    "\n",
    "Note that just because you can download sequence data and parse it into a SeqRecord object in one go doesn’t mean this is a good idea. In general, you should probably download sequences once and save them to a file for reuse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.1 Parsing GenBank records from the net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Section ‍9.6** talks about the Entrez EFetch interface in more detail, but for now let’s just connect to the NCBI and get a few Opuntia (prickly-pear) sequences from GenBank using their GI numbers.\n",
    "\n",
    "First of all, let’s fetch just one record. If you don’t care about the annotations and features downloading a FASTA file is a good choice as these are compact. Now remember, when you expect the handle to contain one and only one record, use the Bio.SeqIO.read() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AF191665.1 with 0 features\n"
     ]
    }
   ],
   "source": [
    "from Bio import Entrez\n",
    "from Bio import SeqIO\n",
    "\n",
    "Entrez.email = \"A.N.Other@example.com\"\n",
    "with Entrez.efetch(\n",
    "    db=\"nucleotide\", rettype=\"fasta\", retmode=\"text\", id=\"6273291\"\n",
    ") as handle:\n",
    "    seq_record = SeqIO.read(handle, \"fasta\")\n",
    "print(\"%s with %i features\" % (seq_record.id, len(seq_record.features)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NCBI will also let you ask for the file in other formats, in particular as a GenBank file. Until Easter 2009, the Entrez EFetch API let you use “genbank” as the return type, however the NCBI now insist on using the official return types of “gb” (or “gp” for proteins) as described on EFetch for Sequence and other Molecular Biology Databases. As a result, in Biopython 1.50 onwards, we support “gb” as an alias for “genbank” in `Bio.SeqIO`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AF191665.1 with 3 features\n"
     ]
    }
   ],
   "source": [
    "from Bio import Entrez\n",
    "from Bio import SeqIO\n",
    "\n",
    "Entrez.email = \"A.N.Other@example.com\"\n",
    "with Entrez.efetch(\n",
    "    db=\"nucleotide\", rettype=\"gb\", retmode=\"text\", id=\"6273291\"\n",
    ") as handle:\n",
    "    seq_record = SeqIO.read(handle, \"gb\")  # using \"gb\" as an alias for \"genbank\"\n",
    "print(\"%s with %i features\" % (seq_record.id, len(seq_record.features)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let’s fetch several records. This time the handle contains multiple records, so we must use the Bio.SeqIO.parse() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AF191665.1 Opuntia marenae rpl16 gene; chloroplast gene for c...\n",
      "Sequence length 902, 3 features, from: chloroplast Grusonia marenae\n",
      "AF191664.1 Opuntia clavata rpl16 gene; chloroplast gene for c...\n",
      "Sequence length 899, 3 features, from: chloroplast Grusonia clavata\n",
      "AF191663.1 Opuntia bradtiana rpl16 gene; chloroplast gene for...\n",
      "Sequence length 899, 3 features, from: chloroplast Grusonia bradtiana\n"
     ]
    }
   ],
   "source": [
    "from Bio import Entrez\n",
    "from Bio import SeqIO\n",
    "\n",
    "Entrez.email = \"A.N.Other@example.com\"\n",
    "with Entrez.efetch(\n",
    "    db=\"nucleotide\", rettype=\"gb\", retmode=\"text\", id=\"6273291,6273290,6273289\"\n",
    ") as handle:\n",
    "    for seq_record in SeqIO.parse(handle, \"gb\"):\n",
    "        print(\"%s %s...\" % (seq_record.id, seq_record.description[:50]))\n",
    "        print(\n",
    "            \"Sequence length %i, %i features, from: %s\"\n",
    "            % (\n",
    "                len(seq_record),\n",
    "                len(seq_record.features),\n",
    "                seq_record.annotations[\"source\"],\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.2 Parsing SwissProt sequences from the net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s use a handle to download a SwissProt file from ExPASy, something covered in more depth in Chapter ‍10. As mentioned above, when you expect the handle to contain one and only one record, use the `Bio.SeqIO.read()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O23729\n",
      "CHS3_BROFI\n",
      "RecName: Full=Chalcone synthase 3; EC=2.3.1.74; AltName: Full=Naringenin-chalcone synthase 3;\n",
      "Seq('MAPAMEEIRQAQRAEGPAAVLAIGTSTPPNALYQADYPDYYFRITKSEHLTELK...GAE')\n",
      "Length 394\n",
      "['Acyltransferase', 'Flavonoid biosynthesis', 'Transferase']\n"
     ]
    }
   ],
   "source": [
    "from Bio import ExPASy\n",
    "from Bio import SeqIO\n",
    "\n",
    "with ExPASy.get_sprot_raw(\"O23729\") as handle:\n",
    "    seq_record = SeqIO.read(handle, \"swiss\")\n",
    "print(seq_record.id)\n",
    "print(seq_record.name)\n",
    "print(seq_record.description)\n",
    "print(repr(seq_record.seq))\n",
    "print(\"Length %i\" % len(seq_record))\n",
    "print(seq_record.annotations[\"keywords\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Sequence files as Dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looping over the iterator returned by` SeqIO.parse` once will exhaust the file. For self-indexed files, such as files in the twoBit format, the return value of `SeqIO.parse` can also be used as a dictionary, allowing random access to the sequence contents. As in this case parsing is done on demand, the file must remain open as long as the sequence data is being accessed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'sequence.bigendian.2bit'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-4194911df358>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mBio\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSeqIO\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mhandle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"sequence.bigendian.2bit\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mrecords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSeqIO\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"twobit\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'sequence.bigendian.2bit'"
     ]
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "handle = open(\"sequence.bigendian.2bit\", \"rb\")\n",
    "records = SeqIO.parse(handle, \"twobit\")\n",
    "records.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For other file formats, Bio.SeqIO provides three related functions module which allow dictionary like random access to a multi-sequence file. There is a trade off here between flexibility and memory usage. In summary:\n",
    "\n",
    "- `Bio.SeqIO.to_dict()` is the most flexible but also the most memory demanding option (see Section ‍5.4.1). This is basically a helper function to build a normal Python dictionary with each entry held as a SeqRecord object in memory, allowing you to modify the records.\n",
    "-` Bio.SeqIO.index()` is a useful middle ground, acting like a read only dictionary and parsing sequences into SeqRecord objects on demand (see Section ‍5.4.2).\n",
    "- `Bio.SeqIO.index_db()` also acts like a read only dictionary but stores the identifiers and file offsets in a file on disk (as an SQLite3 database), meaning it has very low memory requirements (see Section ‍5.4.3), but will be a little bit slower."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4.1 Sequence files as Dictionaries – In memory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next thing that we’ll do with our ubiquitous orchid files is to show how to index them and access them like a database using the Python dictionary data type (like a hash in Perl). This is very useful for moderately large files where you only need to access certain elements of the file, and makes for a nice quick ’n dirty database. For dealing with larger files where memory becomes a problem, see Section ‍5.4.2 below.\n",
    "\n",
    "You can use the function `Bio.SeqIO.to_dict()` to make a SeqRecord dictionary (in memory). By default this will use each record’s identifier (i.e. the .id attribute) as the key. Let’s try this using our GenBank file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "_path = \"data/\"\n",
    "orchid_dict = SeqIO.to_dict(SeqIO.parse( _path + \"ls_orchid.gbk\", \"genbank\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is just one required argument for `Bio.SeqIO.to_dict()`, a list or generator giving SeqRecord objects. Here we have just used the output from the SeqIO.parse function. As the name suggests, this returns a Python dictionary.\n",
    "\n",
    "Since this variable orchid_dict is an ordinary Python dictionary, we can look at all of the keys we have available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(orchid_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Z78533.1',\n",
       " 'Z78532.1',\n",
       " 'Z78531.1',\n",
       " 'Z78530.1',\n",
       " 'Z78529.1',\n",
       " 'Z78527.1',\n",
       " 'Z78526.1',\n",
       " 'Z78525.1',\n",
       " 'Z78524.1',\n",
       " 'Z78523.1',\n",
       " 'Z78522.1',\n",
       " 'Z78521.1',\n",
       " 'Z78520.1',\n",
       " 'Z78519.1',\n",
       " 'Z78518.1',\n",
       " 'Z78517.1',\n",
       " 'Z78516.1',\n",
       " 'Z78515.1',\n",
       " 'Z78514.1',\n",
       " 'Z78513.1',\n",
       " 'Z78512.1',\n",
       " 'Z78511.1',\n",
       " 'Z78510.1',\n",
       " 'Z78509.1',\n",
       " 'Z78508.1',\n",
       " 'Z78507.1',\n",
       " 'Z78506.1',\n",
       " 'Z78505.1',\n",
       " 'Z78504.1',\n",
       " 'Z78503.1',\n",
       " 'Z78502.1',\n",
       " 'Z78501.1',\n",
       " 'Z78500.1',\n",
       " 'Z78499.1',\n",
       " 'Z78498.1',\n",
       " 'Z78497.1',\n",
       " 'Z78496.1',\n",
       " 'Z78495.1',\n",
       " 'Z78494.1',\n",
       " 'Z78493.1',\n",
       " 'Z78492.1',\n",
       " 'Z78491.1',\n",
       " 'Z78490.1',\n",
       " 'Z78489.1',\n",
       " 'Z78488.1',\n",
       " 'Z78487.1',\n",
       " 'Z78486.1',\n",
       " 'Z78485.1',\n",
       " 'Z78484.1',\n",
       " 'Z78483.1',\n",
       " 'Z78482.1',\n",
       " 'Z78481.1',\n",
       " 'Z78480.1',\n",
       " 'Z78479.1',\n",
       " 'Z78478.1',\n",
       " 'Z78477.1',\n",
       " 'Z78476.1',\n",
       " 'Z78475.1',\n",
       " 'Z78474.1',\n",
       " 'Z78473.1',\n",
       " 'Z78472.1',\n",
       " 'Z78471.1',\n",
       " 'Z78470.1',\n",
       " 'Z78469.1',\n",
       " 'Z78468.1',\n",
       " 'Z78467.1',\n",
       " 'Z78466.1',\n",
       " 'Z78465.1',\n",
       " 'Z78464.1',\n",
       " 'Z78463.1',\n",
       " 'Z78462.1',\n",
       " 'Z78461.1',\n",
       " 'Z78460.1',\n",
       " 'Z78459.1',\n",
       " 'Z78458.1',\n",
       " 'Z78457.1',\n",
       " 'Z78456.1',\n",
       " 'Z78455.1',\n",
       " 'Z78454.1',\n",
       " 'Z78453.1',\n",
       " 'Z78452.1',\n",
       " 'Z78451.1',\n",
       " 'Z78450.1',\n",
       " 'Z78449.1',\n",
       " 'Z78448.1',\n",
       " 'Z78447.1',\n",
       " 'Z78446.1',\n",
       " 'Z78445.1',\n",
       " 'Z78444.1',\n",
       " 'Z78443.1',\n",
       " 'Z78442.1',\n",
       " 'Z78441.1',\n",
       " 'Z78440.1',\n",
       " 'Z78439.1']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(orchid_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Under Python 3 the dictionary methods like “.keys()“ and “.values()“ are iterators rather than lists.\n",
    "list(orchid_dict.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P.supardii 5.8S rRNA gene and ITS1 and ITS2 DNA\n"
     ]
    }
   ],
   "source": [
    "# We can access a single SeqRecord object via the keys and manipulate the object as normal:\n",
    "seq_record = orchid_dict[\"Z78475.1\"]\n",
    "print(seq_record.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq('CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGTTGAGATCACAT...GGT')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_record.seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, it is very easy to create an in memory “database” of our GenBank records. Next we’ll try this for the FASTA file instead.\n",
    "\n",
    "Note that those of you with prior Python experience should all be able to construct a dictionary like this “by hand”. However, typical dictionary construction methods will not deal with the case of repeated keys very nicely. Using the Bio.SeqIO.to_dict() will explicitly check for duplicate keys, and raise an exception if any are found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ddca7c47bb622ce713e794769e08f96798349aee41ba316eee0b2f0866205d87"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
